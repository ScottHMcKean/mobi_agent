{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80b81f0b-e856-45fb-bde1-9f76a62d53d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# MOBI Docs Vector Search\n",
    "This notebook demonstrates how to manually create a vector search table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bf1123a-6719-4e4f-a332-5c4ebc6929d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting databricks-vectorsearch\n",
      "  Downloading databricks_vectorsearch-0.63-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: mlflow in ./.venv/lib/python3.12/site-packages (3.6.0)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (2.32.5)\n",
      "Collecting deprecation>=2 (from databricks-vectorsearch)\n",
      "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: mlflow-skinny<4,>=2.11.3 in ./.venv/lib/python3.12/site-packages (from databricks-vectorsearch) (3.6.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.12.0 in ./.venv/lib/python3.12/site-packages (from databricks-vectorsearch) (6.33.0)\n",
      "Requirement already satisfied: cachetools<7,>=5.0.0 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (6.2.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (8.3.0)\n",
      "Requirement already satisfied: cloudpickle<4 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (3.1.2)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (0.73.0)\n",
      "Requirement already satisfied: fastapi<1 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (0.121.1)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (3.1.45)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (8.7.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-proto<3,>=1.9.0 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (1.38.0)\n",
      "Requirement already satisfied: packaging<26 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (25.0)\n",
      "Requirement already satisfied: pydantic<3,>=2.0.0 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (2.12.4)\n",
      "Requirement already satisfied: python-dotenv<2,>=0.19.0 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (1.2.1)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (6.0.3)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (4.15.0)\n",
      "Requirement already satisfied: uvicorn<1 in ./.venv/lib/python3.12/site-packages (from mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (0.38.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests) (2025.10.5)\n",
      "Requirement already satisfied: google-auth~=2.0 in ./.venv/lib/python3.12/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (2.43.0)\n",
      "Requirement already satisfied: starlette<0.50.0,>=0.40.0 in ./.venv/lib/python3.12/site-packages (from fastapi<1->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (0.49.3)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in ./.venv/lib/python3.12/site-packages (from fastapi<1->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (0.0.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./.venv/lib/python3.12/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./.venv/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (4.9.1)\n",
      "Requirement already satisfied: zipp>=3.20 in ./.venv/lib/python3.12/site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (3.23.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (0.59b0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=2.0.0->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (0.4.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in ./.venv/lib/python3.12/site-packages (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (0.6.1)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in ./.venv/lib/python3.12/site-packages (from starlette<0.50.0,>=0.40.0->fastapi<1->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (4.11.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.12/site-packages (from anyio<5,>=3.6.2->starlette<0.50.0,>=0.40.0->fastapi<1->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (1.3.1)\n",
      "Requirement already satisfied: h11>=0.8 in ./.venv/lib/python3.12/site-packages (from uvicorn<1->mlflow-skinny<4,>=2.11.3->databricks-vectorsearch) (0.16.0)\n",
      "Requirement already satisfied: mlflow-tracing==3.6.0 in ./.venv/lib/python3.12/site-packages (from mlflow) (3.6.0)\n",
      "Requirement already satisfied: Flask-CORS<7 in ./.venv/lib/python3.12/site-packages (from mlflow) (6.0.1)\n",
      "Requirement already satisfied: Flask<4 in ./.venv/lib/python3.12/site-packages (from mlflow) (3.1.2)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in ./.venv/lib/python3.12/site-packages (from mlflow) (1.17.1)\n",
      "Requirement already satisfied: cryptography<47,>=43.0.0 in ./.venv/lib/python3.12/site-packages (from mlflow) (46.0.3)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in ./.venv/lib/python3.12/site-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in ./.venv/lib/python3.12/site-packages (from mlflow) (3.4.3)\n",
      "Requirement already satisfied: gunicorn<24 in ./.venv/lib/python3.12/site-packages (from mlflow) (23.0.0)\n",
      "Requirement already satisfied: huey<3,>=2.5.0 in ./.venv/lib/python3.12/site-packages (from mlflow) (2.5.4)\n",
      "Requirement already satisfied: matplotlib<4 in ./.venv/lib/python3.12/site-packages (from mlflow) (3.10.7)\n",
      "Requirement already satisfied: numpy<3 in ./.venv/lib/python3.12/site-packages (from mlflow) (1.26.4)\n",
      "Requirement already satisfied: pandas<3 in ./.venv/lib/python3.12/site-packages (from mlflow) (2.3.3)\n",
      "Requirement already satisfied: pyarrow<23,>=4.0.0 in ./.venv/lib/python3.12/site-packages (from mlflow) (22.0.0)\n",
      "Requirement already satisfied: scikit-learn<2 in ./.venv/lib/python3.12/site-packages (from mlflow) (1.7.2)\n",
      "Requirement already satisfied: scipy<2 in ./.venv/lib/python3.12/site-packages (from mlflow) (1.16.3)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in ./.venv/lib/python3.12/site-packages (from mlflow) (2.0.44)\n",
      "Requirement already satisfied: Mako in ./.venv/lib/python3.12/site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\n",
      "Requirement already satisfied: cffi>=2.0.0 in ./.venv/lib/python3.12/site-packages (from cryptography<47,>=43.0.0->mlflow) (2.0.0)\n",
      "Requirement already satisfied: blinker>=1.9.0 in ./.venv/lib/python3.12/site-packages (from Flask<4->mlflow) (1.9.0)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in ./.venv/lib/python3.12/site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in ./.venv/lib/python3.12/site-packages (from Flask<4->mlflow) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in ./.venv/lib/python3.12/site-packages (from Flask<4->mlflow) (3.0.3)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in ./.venv/lib/python3.12/site-packages (from Flask<4->mlflow) (3.1.3)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in ./.venv/lib/python3.12/site-packages (from graphene<4->mlflow) (3.2.7)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in ./.venv/lib/python3.12/site-packages (from graphene<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in ./.venv/lib/python3.12/site-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib<4->mlflow) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib<4->mlflow) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib<4->mlflow) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib<4->mlflow) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./.venv/lib/python3.12/site-packages (from matplotlib<4->mlflow) (3.2.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas<3->mlflow) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas<3->mlflow) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn<2->mlflow) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.12/site-packages (from cffi>=2.0.0->cryptography<47,>=43.0.0->mlflow) (2.23)\n",
      "Downloading databricks_vectorsearch-0.63-py3-none-any.whl (19 kB)\n",
      "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: deprecation, databricks-vectorsearch\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [databricks-vectorsearch]\n",
      "\u001b[1A\u001b[2KSuccessfully installed databricks-vectorsearch-0.63 deprecation-2.1.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%restart_python` not found.\n"
     ]
    }
   ],
   "source": [
    "%pip install databricks-vectorsearch mlflow requests\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ead7dfa-935a-4b25-b781-77db1f14fb6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Setup: minimal deps + add src to sys.path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "src_path = Path.cwd() / \"src\"\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "776cc63b-68c7-4312-ad89-0263b9625157",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using catalog.schema: max-howarth-demos.vancouver-hackathon-1125\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "CONFIG = mlflow.models.ModelConfig(development_config='config.yaml')\n",
    "\n",
    "CATALOG = CONFIG.get(\"catalog\")\n",
    "SCHEMA = CONFIG.get(\"schema\")\n",
    "print(f\"Using catalog.schema: {CATALOG}.{SCHEMA}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a51a8ff-da68-4368-83cd-95c3023cc502",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>main_heading</th>\n",
       "      <th>scraped_at</th>\n",
       "      <th>status</th>\n",
       "      <th>content_md</th>\n",
       "      <th>site_page_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.mobibikes.ca/</td>\n",
       "      <td>Vancouver Bike Share - Mobi by Rogers</td>\n",
       "      <td>Rogers and Mobi by Rogers provide Vancouver with an easy, convenient, and fun way to get around and explore our beautiful city!</td>\n",
       "      <td></td>\n",
       "      <td>2025-11-13 02:12:17.015559</td>\n",
       "      <td>success</td>\n",
       "      <td># Vancouver Bike Share - Mobi by Rogers\\n\\n**URL:** http://www.mobibikes.ca/\\n**Description:** Rogers and Mobi by Rogers provide Vancouver with an easy, convenient, and fun way to get around and explore our beautiful city!\\n**Main Heading:** \\n**Scraped:** 2025-11-13 02:12:17\\n\\n---\\n\\n![](https://storage.googleapis.com/mobi-customer-website/map_preview_desktop_b717a63b7e/map_preview_desktop_b717a63b7e.jpg)\\n\\n#### Find a Bike\\n\\n[Open Map](/en/map)\\n\\n![](https://storage.googleapis.com/mobi-customer-website/Mobi_David_Niddrie_Photo_Dec2023_High_Res_5684_1_e334000d78/Mobi_David_Niddrie_Photo_Dec2023_High_Res_5684_1_e334000d78.jpg)\\n\\n#### Pricing\\n\\n[Choose a plan](/en/offers-subscription)\\n\\n![](https://storage.googleapis.com/mobi-customer-website/placeholder_p18l_PGOA_1_1_1_02d33c3e87/placeholder_p18l_PGOA_1_1_1_02d33c3e87.jpg)\\n\\n### Introducing Mobi by Rogers!\\n\\nVancouver Bike Share is proud to have Rogers as our system-wide presenting partner of Mobi by Rogers. With common values and practices, connectivity, and smart technology, Rogers and Mobi by Rogers provide Vancouver with an easy, convenient, and fun way to get around and explore our beautiful city!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.mobibikes.ca/en/</td>\n",
       "      <td>Vancouver Bike Share - Mobi by Rogers</td>\n",
       "      <td>Rogers and Mobi by Rogers provide Vancouver with an easy, convenient, and fun way to get around and explore our beautiful city!</td>\n",
       "      <td></td>\n",
       "      <td>2025-11-13 02:12:20.426823</td>\n",
       "      <td>success</td>\n",
       "      <td># Vancouver Bike Share - Mobi by Rogers\\n\\n**URL:** http://www.mobibikes.ca/en/\\n**Description:** Rogers and Mobi by Rogers provide Vancouver with an easy, convenient, and fun way to get around and explore our beautiful city!\\n**Main Heading:** \\n**Scraped:** 2025-11-13 02:12:20\\n\\n---\\n\\n![](https://storage.googleapis.com/mobi-customer-website/map_preview_desktop_b717a63b7e/map_preview_desktop_b717a63b7e.jpg)\\n\\n#### Find a Bike\\n\\n[Open Map](/en/map)\\n\\n![](https://storage.googleapis.com/mobi-customer-website/Mobi_David_Niddrie_Photo_Dec2023_High_Res_5684_1_e334000d78/Mobi_David_Niddrie_Photo_Dec2023_High_Res_5684_1_e334000d78.jpg)\\n\\n#### Pricing\\n\\n[Choose a plan](/en/offers-subscription)\\n\\n![](https://storage.googleapis.com/mobi-customer-website/placeholder_p18l_PGOA_1_1_1_02d33c3e87/placeholder_p18l_PGOA_1_1_1_02d33c3e87.jpg)\\n\\n### Introducing Mobi by Rogers!\\n\\nVancouver Bike Share is proud to have Rogers as our system-wide presenting partner of Mobi by Rogers. With common values and practices, connectivity, and smart technology, Rogers and Mobi by Rogers provide Vancouver with an easy, convenient, and fun way to get around and explore our beautiful city!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.mobibikes.ca/en/#blocks-banner</td>\n",
       "      <td>Vancouver Bike Share - Mobi by Rogers</td>\n",
       "      <td>Rogers and Mobi by Rogers provide Vancouver with an easy, convenient, and fun way to get around and explore our beautiful city!</td>\n",
       "      <td></td>\n",
       "      <td>2025-11-13 02:12:30.361705</td>\n",
       "      <td>success</td>\n",
       "      <td># Vancouver Bike Share - Mobi by Rogers\\n\\n**URL:** http://www.mobibikes.ca/en/#blocks-banner\\n**Description:** Rogers and Mobi by Rogers provide Vancouver with an easy, convenient, and fun way to get around and explore our beautiful city!\\n**Main Heading:** \\n**Scraped:** 2025-11-13 02:12:30\\n\\n---\\n\\n![](https://storage.googleapis.com/mobi-customer-website/map_preview_desktop_b717a63b7e/map_preview_desktop_b717a63b7e.jpg)\\n\\n#### Find a Bike\\n\\n[Open Map](/en/map)\\n\\n![](https://storage.googleapis.com/mobi-customer-website/Mobi_David_Niddrie_Photo_Dec2023_High_Res_5684_1_e334000d78/Mobi_David_Niddrie_Photo_Dec2023_High_Res_5684_1_e334000d78.jpg)\\n\\n#### Pricing\\n\\n[Choose a plan](/en/offers-subscription)\\n\\n![](https://storage.googleapis.com/mobi-customer-website/placeholder_p18l_PGOA_1_1_1_02d33c3e87/placeholder_p18l_PGOA_1_1_1_02d33c3e87.jpg)\\n\\n### Introducing Mobi by Rogers!\\n\\nVancouver Bike Share is proud to have Rogers as our system-wide presenting partner of Mobi by Rogers. With common values and practices, connectivity, and smart technology, Rogers and Mobi by Rogers provide Vancouver with an easy, convenient, and fun way to get around and explore our beautiful city!</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.mobibikes.ca/en/community-pass</td>\n",
       "      <td>Community Pass - Mobi by Rogers</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2025-11-13 02:12:27.503333</td>\n",
       "      <td>success</td>\n",
       "      <td># Community Pass - Mobi by Rogers\\n\\n**URL:** http://www.mobibikes.ca/en/community-pass\\n**Description:** \\n**Main Heading:** \\n**Scraped:** 2025-11-13 02:12:27\\n\\n---\\n\\nOur Community Pass program, first launched in 2018, makes bike share more accessible and affordable. Now even more people can enjoy the benefits of biking in Vancouver through discounted memberships and cash payment options.\\n\\n#### You may qualify for this pass if you have a:\\n\\n\\*No credit card required. Cash, debit and e-transfer available.\\n\\n- ##### 1\\n\\n  Leisure Access Pass\\n- ##### 2\\n\\n  Red Compass Card\\n- ##### 3\\n\\n  Greater Vancouver Food Bank Membership\\n- ##### 4\\n\\n  Proof of Annual Income Less Than $38,000\\n- ##### 5\\n\\n  Third Party Referral from a Community Partner\\n- ##### 6\\n\\n  A Persons With Disabilities Designation\\n\\n![](https://storage.googleapis.com/mobi-customer-website/placeholder_Mobi_David_Niddrie_Photo_Dec2023_High_Res_6329_1_4f9f8a6b17/placeholder_Mobi_David_Niddrie_Photo_Dec2023_High_Res_6329_1_4f9f8a6b17.jpg)\\n\\n### Applying for the first time?\\n\\n#### Community Pass\\n\\nIncludes unlimited 60-minute rides on Classic Bikes ONLY!\\n\\n- Classic Bikes: Unlimited 60-minute rides, $0.25/min thereafter\\n- Ebikes: NO ACCESS\\n\\n[Apply](https://docs.google.com/forms/d/e/1FAIpQLSelVv7lmwppyGPgF3l6HzrQVHWwJjHi89e-C24Vunc4bJxa1A/viewform)\\n\\nDetails\\n\\nClassic Bikes – $0.25/minute if you exceed the 60-minute ride limit\\nNo Ebike Access\\n\\n#### Community Pass (Ebike)\\n\\nIncludes unlimited 60-minute rides on Classic Bikes. Ebikes available for $0.35.\\n\\n- Classic Bikes: Unlimited 60-minute rides, $0.25/min thereafter\\n- Ebikes: $0.15/min for the first 60 minutes, $0.35/min thereafter\\n- Credit card required.\\n\\n[Apply](https://docs.google.com/forms/d/e/1FAIpQLSelVv7lmwppyGPgF3l6HzrQVHWwJjHi89e-C24Vunc4bJxa1A/viewform)\\n\\nDetails\\n\\nThis pass requires a credit card on file.\\nClassic Bikes – $0.25/minute if you exceed the 60-minute ride limit.\\nEbikes – $0.35/min\\n\\n#### Community Pass (PWD)\\n\\nIncludes unlimited 60-minute rides on both Classic Bikes &amp; Ebikes.\\n\\n- Classic Bikes: Unlimited 60-minute rides, $0.25/min thereafter.\\n- Ebikes: Unlimited 60-minute rides, $0.35/min thereafter\\n\\n[Apply](https://docs.google.com/forms/d/e/1FAIpQLSelVv7lmwppyGPgF3l6HzrQVHWwJjHi89e-C24Vunc4bJxa1A/viewform)\\n\\nDetails\\n\\nClassic Bikes – $0.25/minute if you exceed the 60-minute ride limit.\\nEbikes – $0.35/minute if you exceed the 60-minute ride limit.\\nRequires proof of PWD designation\\n\\n#### Community Pass (Youth)\\n\\nIncludes unlimited 60-minute rides on Classic Bikes ONLY!\\n\\n- Classic Bikes: Unlimited 60-minute rides, $0.25/min thereafter\\n- Ebikes: NO ACCESS\\n\\n[Apply](https://forms.gle/stZVdr2AtCvnS7Zn6)\\n\\nDetails\\n\\nClassic Bikes – $0.25/minute if you exceed the 60-minute ride limit\\nNo Ebike Access\\n\\n### Renewing your pass?\\n\\n#### Community Pass (Classic, Ebike, or PWD)\\n\\nApply here if you already have a Community Pass (Classic, Ebike, or PWD) and want to renew.\\n\\n[Renew Pass](https://forms.gle/ZuNrHNmPivcS4vVS8)\\n\\nDetails\\n\\nYou will be required to re-submit your eligibility, to ensure it's up to date.\\n\\n#### Community Pass Youth\\n\\nApply here if you already have a Community Pass (Youth) and want to renew.\\n\\n[Renew Pass](https://forms.gle/mo2fr8iQgwcv1fC78)\\n\\nDetails\\n\\nYou will be required to re-submit your eligibility, to confirm it's up to date.\\nStudent ID from a participating Secondary School Required</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.mobibikes.ca/en/corporate</td>\n",
       "      <td>Corporate Membership Program - Mobi by Rogers</td>\n",
       "      <td></td>\n",
       "      <td>Give Your Team the Power to Ride—at a Discount</td>\n",
       "      <td>2025-11-13 02:12:26.839866</td>\n",
       "      <td>success</td>\n",
       "      <td># Corporate Membership Program - Mobi by Rogers\\n\\n**URL:** http://www.mobibikes.ca/en/corporate\\n**Description:** \\n**Main Heading:** Give Your Team the Power to Ride—at a Discount\\n**Scraped:** 2025-11-13 02:12:26\\n\\n---\\n\\n## Give Your Team the Power to Ride—at a Discount\\n\\nMobi by Rogers makes it easy for companies to support sustainable commuting and healthy lifestyles. For a one-time annual fee of just **$500**, your organization can join our Corporate Program, unlocking access to discounted Mobi memberships for all employees.\\n\\nInstead of the regular $169 annual pass, your employees pay only $119 for a year's access to bike share!\\n\\nBy joining, your company supports:\\n\\n- **Active, healthy commuting**\\n- **Lower transportation costs for staff**\\n- **Environmental sustainability and reduced congestion**\\n- **Employee wellness and morale**\\n\\nJoin dozens of forward-thinking Vancouver employers who are helping their teams get around the city more affordably and responsibly.\\n\\n### Are you looking to enrol your company in the Corporate Program?\\n\\n[Company enrolment](https://docs.google.com/forms/d/e/1FAIpQLSeOkCSM4kCecQh1jLxqarv4ny5JZU2Es6gvyGX_asFY5e4DhA/viewform)\\n\\n#### Is your company already enrolled?\\n\\n- ##### 1\\n\\n  Download the Mobi by Rogers App\\n- ##### 2\\n\\n  Sign up for an account\\n- ##### 3\\n\\n  Go to the Wallet section\\n- ##### 4\\n\\n  Enter your company promo code\\n- ##### 5\\n\\n  Enjoy your ride!\\n\\n[Download the app now!](https://www.mobibikes.ca/en/app)\\n\\n![](https://storage.googleapis.com/mobi-customer-website/placeholder_Mobi_David_Niddrie_Photo_July2024_High_Res_3208_copy_d7896211cd/placeholder_Mobi_David_Niddrie_Photo_July2024_High_Res_3208_copy_d7896211cd.jpeg)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://www.mobibikes.ca/en/help</td>\n",
       "      <td>Contact us - Mobi by Rogers</td>\n",
       "      <td>We are happy to assist you! Before reaching out, we invite you to explore our FAQ</td>\n",
       "      <td></td>\n",
       "      <td>2025-11-13 02:12:24.785604</td>\n",
       "      <td>success</td>\n",
       "      <td># Contact us - Mobi by Rogers\\n\\n**URL:** http://www.mobibikes.ca/en/help\\n**Description:** We are happy to assist you! Before reaching out, we invite you to explore our FAQ\\n**Main Heading:** \\n**Scraped:** 2025-11-13 02:12:24\\n\\n---\\n\\n### Questions?\\n\\n[Frequently Asked Questions](https://mobibyrogers.zendesk.com/hc)\\n\\n### Contact us\\n\\nContact:\\n\\n- [+1 (778) 655-1800](tel:+1 (778) 655-1800)\\n- [info@mobibikes.ca](mailto:info@mobibikes.ca)\\n\\nEmail address\\n\\nPhone number\\n\\n+1\\n\\nAC\\n\\nAD\\n\\nAE\\n\\nAF\\n\\nAG\\n\\nAI\\n\\nAL\\n\\nAM\\n\\nAO\\n\\nAR\\n\\nAS\\n\\nAT\\n\\nAU\\n\\nAW\\n\\nAX\\n\\nAZ\\n\\nBA\\n\\nBB\\n\\nBD\\n\\nBE\\n\\nBF\\n\\nBG\\n\\nBH\\n\\nBI\\n\\nBJ\\n\\nBL\\n\\nBM\\n\\nBN\\n\\nBO\\n\\nBQ\\n\\nBR\\n\\nBS\\n\\nBT\\n\\nBW\\n\\nBY\\n\\nBZ\\n\\nCA\\n\\nCC\\n\\nCD\\n\\nCF\\n\\nCG\\n\\nCH\\n\\nCI\\n\\nCK\\n\\nCL\\n\\nCM\\n\\nCN\\n\\nCO\\n\\nCR\\n\\nCU\\n\\nCV\\n\\nCW\\n\\nCX\\n\\nCY\\n\\nCZ\\n\\nDE\\n\\nDJ\\n\\nDK\\n\\nDM\\n\\nDO\\n\\nDZ\\n\\nEC\\n\\nEE\\n\\nEG\\n\\nEH\\n\\nER\\n\\nES\\n\\nET\\n\\nFI\\n\\nFJ\\n\\nFK\\n\\nFM\\n\\nFO\\n\\nFR\\n\\nGA\\n\\nGB\\n\\nGD\\n\\nGE\\n\\nGF\\n\\nGG\\n\\nGH\\n\\nGI\\n\\nGL\\n\\nGM\\n\\nGN\\n\\nGP\\n\\nGQ\\n\\nGR\\n\\nGT\\n\\nGU\\n\\nGW\\n\\nGY\\n\\nHK\\n\\nHN\\n\\nHR\\n\\nHT\\n\\nHU\\n\\nID\\n\\nIE\\n\\nIL\\n\\nIM\\n\\nIN\\n\\nIO\\n\\nIQ\\n\\nIR\\n\\nIS\\n\\nIT\\n\\nJE\\n\\nJM\\n\\nJO\\n\\nJP\\n\\nKE\\n\\nKG\\n\\nKH\\n\\nKI\\n\\nKM\\n\\nKN\\n\\nKP\\n\\nKR\\n\\nKW\\n\\nKY\\n\\nKZ\\n\\nLA\\n\\nLB\\n\\nLC\\n\\nLI\\n\\nLK\\n\\nLR\\n\\nLS\\n\\nLT\\n\\nLU\\n\\nLV\\n\\nLY\\n\\nMA\\n\\nMC\\n\\nMD\\n\\nME\\n\\nMF\\n\\nMG\\n\\nMH\\n\\nMK\\n\\nML\\n\\nMM\\n\\nMN\\n\\nMO\\n\\nMP\\n\\nMQ\\n\\nMR\\n\\nMS\\n\\nMT\\n\\nMU\\n\\nMV\\n\\nMW\\n\\nMX\\n\\nMY\\n\\nMZ\\n\\nNA\\n\\nNC\\n\\nNE\\n\\nNF\\n\\nNG\\n\\nNI\\n\\nNL\\n\\nNO\\n\\nNP\\n\\nNR\\n\\nNU\\n\\nNZ\\n\\nOM\\n\\nPA\\n\\nPE\\n\\nPF\\n\\nPG\\n\\nPH\\n\\nPK\\n\\nPL\\n\\nPM\\n\\nPR\\n\\nPS\\n\\nPT\\n\\nPW\\n\\nPY\\n\\nQA\\n\\nRE\\n\\nRO\\n\\nRS\\n\\nRU\\n\\nRW\\n\\nSA\\n\\nSB\\n\\nSC\\n\\nSD\\n\\nSE\\n\\nSG\\n\\nSH\\n\\nSI\\n\\nSJ\\n\\nSK\\n\\nSL\\n\\nSM\\n\\nSN\\n\\nSO\\n\\nSR\\n\\nSS\\n\\nST\\n\\nSV\\n\\nSX\\n\\nSY\\n\\nSZ\\n\\nTA\\n\\nTC\\n\\nTD\\n\\nTG\\n\\nTH\\n\\nTJ\\n\\nTK\\n\\nTL\\n\\nTM\\n\\nTN\\n\\nTO\\n\\nTR\\n\\nTT\\n\\nTV\\n\\nTW\\n\\nTZ\\n\\nUA\\n\\nUG\\n\\nUS\\n\\nUY\\n\\nUZ\\n\\nVA\\n\\nVC\\n\\nVE\\n\\nVG\\n\\nVI\\n\\nVN\\n\\nVU\\n\\nWF\\n\\nWS\\n\\nXK\\n\\nYE\\n\\nYT\\n\\nZA\\n\\nZM\\n\\nZW\\n\\nMessage\\n\\nI agree that my data will be stored and processed in accordance with the [privacy policy](/privacy-policy) and I accept the [general terms of use](/terms-and-conditions) of the service.\\n\\nSend</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>http://www.mobibikes.ca/en/jobs</td>\n",
       "      <td>Jobs - Mobi by Rogers</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2025-11-13 02:12:26.260092</td>\n",
       "      <td>success</td>\n",
       "      <td># Jobs - Mobi by Rogers\\n\\n**URL:** http://www.mobibikes.ca/en/jobs\\n**Description:** \\n**Main Heading:** \\n**Scraped:** 2025-11-13 02:12:26\\n\\n---\\n\\n#### WORK TOWARDS A BETTER FUTURE\\n\\nWant to work in a fun and dynamic environment with passionate people? Apply to one of our current opportunities by emailing [jobs@mobibikes.ca](mailto:jobs@mobibikes.ca). Please include your resume, cover letter and the name of the position you are applying for.  \\n  \\nWe acknowledge that Mobi by Rogers operates on the unceded, occupied, ancestral and traditional homelands of the xʷməθkwəy̓əm (Musqueam), Skwxwú7mesh (Squamish) and Səl̓ílwətaʔ/Selilwitulh (Tsleil-Waututh) Nations.\\n\\n#### CURRENT OPPORTUNITIES:\\n\\n#### [Bike Share Fleet Balancer – Permanent Full-Time](https://drive.google.com/file/d/1XYf8WxT59Hnhjq7LMZcTPQbd9bUSyTVX/view?usp=sharing)\\n\\n#### Don't see any openings that are a good fit but still want to work with us? Just email us at [jobs@mobibikes.ca](mailto:jobs@mobibikes.ca) and tell us about yourself!\\n\\n#### WHY JOIN MOBI BY ROGERS?\\n\\n- Competitive wages\\n- Extended health and dental benefits plan for eligible full-time and part-time employees\\n- Flexible scheduling &amp; some remote working possible (position dependant)\\n- Free use of Mobi by Rogers classic bikes and ebikes\\n- Secure bike parking and shower facilities at HQ\\n- Free period products in bathrooms\\n- Free bike tune-ups &amp; repairs by our mechanics\\n- Discounts on industry gear and services\\n- Friends &amp; family discounted membership pricing\\n- Work with others who are passionate about bikes and the sharing economy\\n\\nWe are committed to employment equity and encourage applications from people whose identity has typically been underrepresented in the cycling industry or community. This includes Indigenous persons, persons of colour, persons with disabilities, and trans and non-binary persons. We value the experiences and skills gained through non-traditional employment, including unpaid labour and community organizing. At Mobi, we are committed to recruiting and retaining a diverse workforce that represents the community we serve. Accommodations will be provided upon request during the selection process.</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>http://www.mobibikes.ca/en/legal-notice</td>\n",
       "      <td>legal notices - Mobi by Rogers</td>\n",
       "      <td></td>\n",
       "      <td>legal notices</td>\n",
       "      <td>2025-11-13 02:12:29.058613</td>\n",
       "      <td>success</td>\n",
       "      <td># legal notices - Mobi by Rogers\\n\\n**URL:** http://www.mobibikes.ca/en/legal-notice\\n**Description:** \\n**Main Heading:** legal notices\\n**Scraped:** 2025-11-13 02:12:29\\n\\n---\\n\\n# legal notices\\n\\n**VANCOUVER BIKE SHARE RENTAL AGREEMENT &amp; WAIVER (“AGREEMENT”)**\\n\\nPLEASE READ THIS AGREEMENT CAREFULLY BEFORE RENTING OR USING A CLASSIC BICYCLE (“**CLASSIC BIKE**”) OR ELECTRIC BIKE (“**EBIKE**”) (CLASSIC BIKES AND EBIKES ARE EACH REFERRED TO HEREIN AS A “**BIKE**”) FROM VANCOUVER BIKE SHARE INC. AND CYCLEHOP, LLC dba MOBI BY ROGERS GO OR ANY OF THEIR AFFILIATES (COLLECTIVELY, \"**VBS**\"); VBS AND SMOOVE SAS. ARE JOINTLY REFERRED TO HEREIN AS \"**OPERATOR**\".\\n\\nBY RENTING OR USING A BIKE, YOU AGREE TO ALL OF THE TERMS AND CONDITIONS CONTAINED WITHIN THIS AGREEMENT, INCLUDING, BUT NOT LIMITED TO, THE WAIVERS, RELEASES AND LIMITATIONS OF LIABILITY SET FORTH HEREIN. YOUR CONSENT IS EFFECTIVE IMMEDIATELY FOLLOWING YOUR ACCEPTANCE OF THIS AGREEMENT.  IF YOU DO NOT AGREE WITH ALL OF THE TERMS AND CONDITIONS OF USE SET FORTH IN THIS AGREEMENT, YOU ARE NOT PERMITTED TO RENT OR USE A BIKE FROM OPERATOR OR ITS AFFILIATES.\\n\\nTAKE NOTE THAT TO PURCHASE A RENTAL PLAN (“**PASS**” or “**MEMBERSHIP**”) AND/OR TO RENT A BIKE, YOU MUST BE AT LEAST: (i) FOR EBIKES, 19 YEARS OF AGE; or (ii) FOR CLASSIC BIKES, 12 YEARS OF AGE AND ASSISTED BY AN ADULT IN THE MANNER OUTLINED IN THIS AGREEMENT.\\n\\nPARTIES, CONSIDERATION AND BIKE SHARE PROGRAM DESCRIPTION\\n\\n1.              AGREEMENT.  This Agreement is between the user (“**you**” or “**Rider**”) and the Operator.\\n\\n1.1           CONSIDERATION:  In consideration of the Operator renting a Bike to you, you agree to all the terms, conditions and provisions contained within this Agreement.\\n\\n1.2           EQUIPMENT.  The Operator maintains a network of hub stations (“**Stations**”) where Bikes are docked at Bike racks (“**Rack**”) using an electronically controlled lock (“**Lock**”). Signs are located at some Stations which provide instructions for payment. Bikes are equipped with Smoove Box devices. All of the foregoing equipment and other equipment located at a Station or that consists of any Bike, in whole or part, is referred to herein as “**Operator Equipment**.”\\n\\n1.3           HOW IT WORKS.\\n\\n(a)            REGISTRATION AND PURCHASE.  You must register for a Rider account (“**Account**”), including providing credit card info in accordance with Section 2.11, and purchase a Pass or Membership via: (i) the Operator’s website; (ii) the mobile app; or (iii) other applicable third party apps. These registration and payment obligations do not apply to VIP group passes or community passes that are registered and paid for separately; note however that the other obligations set out in this Agreement still apply to Riders holding VIP group or community passes.\\n\\n(b)            METHOD OF RENTAL.  Once you have acquired a Pass or Membership, you can rent an available Bike in one of the following ways: (i) enter your Account number and PIN code at the Smoove Box located on the Bike; or (ii) tap your Membership card and enter your PIN code at the Smoove Box located on the Bike. Group rides organized separately with the Operator may also enable access to Bikes to applicable Riders; take note that such Riders are still subject to the terms and conditions of this Agreement.\\n\\n(c)            RENTAL PERIOD.  Your Bike rental period (“**Rental Period**”) begins when the Bike is unlocked from a Rack at a Station. You take the Bike for a trip (“**Trip**”), and the Rental Period ends when the Bike is returned to a Station. To end the Rental Period, you must lock the Bike to an available Rack, and wait for verification on the Bike screen, Return OK, and audio signal of one beep, indicating the Rental Period has ended prior to leaving the Bike. If Rider has difficulty ending a Trip, Rider must make reasonable effort to troubleshoot the situation such as but not limited to removing the Bike from the Rack to retry ending the Trip, using a different available Rack in the same Station, or using a Rack in an alternative Station. If the difficulty persists, Rider must contact Operator at 778-655-1800 or info@mobibikes.ca for assistance. In accordance with Section 2.8, fees, in addition to any applicable overage fees, may be applied to Rider for Trips where the Rental Period has not been properly ended as determined by the Operator in its sole discretion.\\n\\n(d)            STOPOVER.  Stopover is a feature of every Bike that allows you to secure and lock your Bike outside of a station. It is meant for quick stops or short breaks taken away from the Bike. Your Trip time will still be counted while the Bike is out of a Station and will contribute to incurring overage fees, if applicable. To engage Stopover, press “Enter” on the screen, scan your card if applicable, and enter your PIN. Remove the cable lock from the right side of the handle bar and loop it around a secure structure in a secure location (take note that a failure to adequately secure the Bike may lead to fees charged in accordance with Section 10 for lost or stolen Bikes). To disengage stopover, simply press “Enter” on the screen again and input your PIN.\\n\\n(e)            BOUNDARIES.  All Trips must begin and end at a Station. Trips cannot terminate outside of the VBS program area designated on the map posted at each Station or available on the website and app (“**Program Area**”), and any Bike left outside the Program Area will be considered stolen with fees charged in accordance with Section 2.7.\\n\\n2.              RENTAL RULES.\\n\\n2.1           RENTAL PLANS.  \\n\\n(a)            You may acquire from the Operator a rental plan at the applicable rate structure posted by the Operator from time to time on (i) the Operator’s website; (ii) the mobile app; or (iii) other applicable third party apps.\\n\\n(b)            You are responsible for payment of the rate corresponding to the rental plan that you select, which rental plan may entail different pricing depending on rentals for Classic Bikes and Ebikes.\\n\\n(c)            The Operator may, at its sole discretion, offer, from time to time, sales on select rental plans, special group pricing, and/or community passes, and may establish corresponding terms and conditions, including (but not limited to) with respect to eligibility, availability and pricing thereof.\\n\\n2.2           AUTOMATIC RENEWAL. Unless otherwise provided by the Operator or in this Agreement, all the following Passes and Membership are automatically renewed unless cancelled at least one (1) day prior to the end of their term:\\n\\n(a)            all annual memberships (sale memberships renew as regular priced memberships), except Community Passes; and\\n\\n(b)            all monthly memberships.\\n\\nTo remove auto-renew on or cancel a Pass or Membership, Riders must login to their Account at [www.mobibikes.ca](http://www.mobibikes.ca/) or on the Operator mobile app and carry out the steps outlined therein to cancel their Pass or Membership.\\n\\n2.3           UNUSED RENTAL TIME. Any unused rental time under a Pass or Membership cannot be carried over from one day to another day. For example, if you purchase a 30 Day Pass and do not rent a Bike on a given day within the applicable 30 day-period, you are not permitted to “bank” time from that calendar day to any other day.\\n\\n2.4           OVERAGE FEES.  You will be charged overage fees when a Trip exceeds the time period corresponding to the particular Pass or Membership you have purchased, as set out in Section 10.1. You hereby agree to pay all overage fees incurred under your particular Pass or Membership. You assume all risks and responsibilities for tracking the duration of each Trip undertaken pursuant to your Pass or Membership. All overage fees are subject to tax.\\n\\n2.5           MAXIMUM RENTAL TIME.  If a Bike is not returned to a Station within 16 hours of the start of a Rental Period (the “**Maximum Rental Time**”), the Operator may, in its sole discretion, deem the Bike to be stolen and charge you fees in accordance with Section 10.\\n\\n2.6           REPAIR FEE.  If a Bike is damaged during your Rental Period of the Bike, beyond regular wear and tear, you will be charged fees in accordance with Section 10.\\n\\n2.7           LOST OR STOLEN BIKE – SUSPENSION AND FEE.\\n\\n(a)            General – Your Account will be suspended in accordance with Section 2.20 if:\\n\\n(i)             you leave a Bike unlocked or unattended and it is stolen;\\n\\n(ii)            a Bike is lost or stolen through your fault as determined by the Operator in its sole discretion; or\\n\\n(iii)           a Bike is not returned to a Station within the Maximum Rental Time set out in Section 2.5.\\n\\nIf stolen, the Rider is responsible for promptly reporting the theft to the police and promptly providing the file number of the police report to the Operator. If the Bike is located, the Operator will complete a full inspection and damage report, as well as a full maintenance check. The Operator will then assess any fees owing pursuant to this Agreement, including fees set out in Section 10 and full replacement costs if the Bike is not found or is significantly damaged when found. If the Operator determines, in its sole discretion, that the loss or theft was not a result of wilful misconduct, gross negligence or repeat system abuse (including repeat breach of this Agreement) by the Rider, then on payment by the Rider of the fees assessed by the Operator (if any), the Operator will reinstate the Rider’s Account.\\n\\n(b)            Community Pass Holder – If a Bike becomes lost, stolen, or damaged while under the care or responsibility of a Rider holding a Community Pass, the Operator may, in its sole discretion:\\n\\n(i)             suspend such Rider from the right to rent any Bike for a period of up to one (1) year; or\\n\\n(ii)            require the Rider to pay a one-time fee of up to $250 for a Classic Bike or $1,500 for an Ebike,\\n\\nand to access a Bike again, the Community Pass holder must first meet with an approved Operator Employee to review proper bike use procedure.\\n\\n(c)            Community Partner Pass holder – If a Bike becomes lost, stolen, or damaged while under the care or responsibility of a Rider holding a non-renewable Annual Pass issued by the Operator to a community partner, the Rider and the applicable community partner are jointly liable for any damages caused. In addition, the Operator may, in its sole discretion:\\n\\n(i)             suspend such Rider from the right to rent any Bike for a period of up to one (1) year; or\\n\\n(ii)            require the Rider and/or the applicable community partner to pay a one-time fee of up to $250 for a Classic Bike or $1,500 for an Ebike.\\n\\nand to access a Bike again, such Rider must first meet with the Operator’s equity program coordinator to review proper bike use procedure.\\n\\n2.8           LATE RETURN FEE.  When the Operator receives a system notification of a Bike that has not been properly docked back into a Station, and no attempt has been made by the Rider to end the Trip as required under Section 1.3(c), the Operator will pardon and/or waive the first occurrence and any resulting overage fees, but will charge a late return fee and overage fees in accordance with Section 10 for all subsequent infractions. Three repeat occurrences of such infractions without promptly contacting the Operator will result in a suspension in accordance to Section 2.20, and corresponding fees that must be paid by the Rider to the Operator before the Account suspension is lifted by the Operator.\\n\\n2.9           HELMET USAGE.  You expressly acknowledge that applicable laws and ordinances require each Rider to wear an appropriate protective helmet designed for riding bicycles. You are solely responsible for yourself and any other permitted users who are renting Bikes under your Account to ensure that each of you wears a helmet and complies with the law. For convenience, a Mobi helmet (“**Helmet**”) is attached to each Bike or is available elsewhere as indicated on Station signs or the Bike Share Program website – and its use is included in the Bike rental fee or other payment as indicated. Helmets are only provided for use during a Rental Period and must be returned at the same time that a Trip is concluded. If you do not return a Helmet, you may be charged a Helmet fee of $50. Failure to wear a helmet while riding a Bike may result in fines, tickets, citations, or loss of ridership privileges, all of which is the sole responsibility of the Rider, and Operator assumes no responsibility or liability whatsoever as a result of a failure to wear a helmet while riding a Bike (including in respect of any property or bodily damage). Helmets are deemed to be included in the definition of “**Bike**” for the purpose of this Agreement.\\n\\n2.10        VIOLATIONS.  You shall be completely responsible, and shall indemnify the Operator, for all tickets and fees assessed against the Bike or the Operator during your Rental Period or as a result of the location where you parked the Bike. You are responsible for all tickets and moving violations incurred during the Rental Period, including those resulting from your failure to wear a helmet. You agree to reimburse the Operator for any costs, expenses and attorney’s fees for processing, pursuing and/or defending any such claims.\\n\\n2.11        CREDIT CARD.\\n\\n(a)            General – Except as otherwise provided in this Section 2.11 you must provide the Operator a valid credit card number with expiration date (“**Credit Card**”) before being registered to use a Bike. This Credit Card will be verified for its validity through a one-time $25 card verification anytime the Credit Card is added to Rider Account and prior to any applicable electronic payment process; such amount will be applied and then immediately cancelled and/or refunded. Pre-paid credit cards are not considered a valid method of payment. By providing your Credit Card to the Operator, you represent and warrant to the Operator that you are authorized to use such Credit Card. You further authorize the Operator to charge the Credit Card for all costs (including fees, expenses and tickets) incurred by you under this Agreement, and acknowledge and agree that all such costs are subject to applicable taxes and other local government charges, which may be charged and collected by the Operator. In the event that your Credit Card is declined for any reason, the Operator may immediately suspend your rental plan and ability to use any Bikes until all of your prior charges are paid in full, including a reinstatement fee of up to $30.\\n\\n(b)            Community Partners – If you hold a Pass issued by the Operator to a community partner, such community partner will be responsible for providing a Credit Card to the Operator and making the authorizations outlined above; however, the applicable community partner may choose to collect all costs, fees and expenses accrued pursuant to this Agreement (including tickets), applicable taxes and local government charges from you if agreed-to in advance with the Operator.\\n\\n(c)            Community Pass Holder – Holders of a Community Pass may, in addition to payment by valid credit card, provide payment for all or any costs, fees and expenses accrued pursuant to this Agreement (including tickets), applicable taxes and local government charges by cash or debit payment using the Square software.\\n\\n2.12        CREDITS.  The Operator may issue time or other credits (“**Credits**”) to you to be used toward future Trips. Credits shall have no monetary value. Credits may be transferred to family or friends as approved by the Operator but may not be sold. No monetary exchange is permitted for Credits on Rider Account. If any Credit has an expiration date, it will be noted in your Account page. Unused Credits will expire and be removed from your Account at the end of any applicable validity period. The terms outlined in this Agreement are applicable to all Bike usage whether or not a Credit is applied to the Trip.\\n\\n2.13        THIRD PARTY PAYMENT PROCESSOR.  \\n\\n(a)            The Operator uses a third party payment processing company called Stripe. In collecting payment, Stripe processes your credit card transactions and obtains personal information from you. Stripe provides some or all of the services from systems located within the United States. As such, your credit card data (“**Card Data**”) and personal information will be transferred, processed and stored outside of Canada on servers in the United States, and may be subject to disclosure as required by applicable law. Stripe may provide the Operator with information such as your name, credit card type, expiration date, and the last four digits of your credit card number. This information is only used to make single payment requests, or register the Rider for an ongoing membership plan that requires automatic payments in the future. For more information on Stripe’s payment processing and security practices, please visit &lt;https://stripe.com/ca/privacy&gt; and &lt;https://stripe.com/ca/terms#section_a&gt;.\\n\\n(b)            Take note that if you object to your personal information and/or Card Data being processed and stored in this manner, you cannot use the Operator’s Bike rental service. By registering for the Bike rental service pursuant to this Agreement and providing valid payment, you expressly consent to the Operator’s use and disclosure of your personal information and Card Data in the manner described in this Agreement. \\n\\n2.14        RENTAL OF MULTIPLE BICYCLES.  Subject to program requirements and availability, a Rider over the age of 19 who purchases a Pay Per Ride Pass may rent up to four (4) Bikes at the same time on that Rider’s Account. If a Rider elects to rent multiple Bikes at the same time, such Rider (referred to as the “**Main Rider**” for the purposes of this Section 2.14) agrees to rent the first Bike for the Main Rider's own use and to make subsequent Bikes available to additional users (each, an “**Additional User**”) under the Main Rider’s Account. Prior to riding, each Additional User must review and accept this Agreement, except such requirements outlined herein to create an Account. The Main Rider further acknowledges and agrees that:\\n\\n(a)            the Main Rider shall be responsible for each Bike rented under the Main Rider's Account;\\n\\n(b)            that each Additional User is at least 12 years of age (for Classic Bikes), and at least 19 years of age (for Ebikes);\\n\\n(c)            the Main Rider is responsible for ensuring that each Additional User reads and complies with this Agreement, except such requirements outlined herein to create an Account; and\\n\\n(d)            the Main Rider is fully and completely responsible and liable for all Claims (as defined in Section 5.1) arising from or related to all Additional User(s)’ use(s) of a Bike/Bikes.\\n\\n2.15        RIDERS 19 YEARS AND OLDER. This Agreement applies to all Additional Users who are at least 19 years of age. Each such Additional Users will be deemed to be a “**Rider**” under this Agreement, with the exception that such Additional Users will not need to set up their own Account, and it is the responsibility of each Rider, including Additional Users, to read and comply with this Agreement, including, without limitation, in respect of Section 5 (Release and Limitation of Liability), Section 6 (Assumptions of Risks Disclaimer) and Section 8 (Indemnification). Any liability of an Additional User under these and other sections of this Agreement will be joint and several with the Main Rider whose Account was used to rent a Bike. Use of any the Operator Equipment will be deemed to be acceptance of the terms of this Agreement.\\n\\n2.16        RIDERS UNDER THE AGE OF 19. In the event that the Main Rider is renting multiple Bikes and one or more of the Additional User(s) is under 19 years of age, the Main Rider agrees to the following:\\n\\nYOU HEREBY AFFIRM THAT:\\n\\n(i)             YOU ARE THE PARENT OR LEGAL GUARDIAN OF EACH ADDITIONAL USER(S) WHO IS UNDER 19 YEARS OF AGE;\\n\\n(ii)            YOU ARE AT LEAST 19 YEARS OF AGE AND EACH ADDITIONAL USER USING A CLASSIC BIKE IS: (i) AT LEAST 12 YEARS OF AGE; AND (ii) AT LEAST 150 CM IN HEIGHT;\\n\\n(iii)           YOU WILL NOT PERMIT ANY ADDITIONAL USER UNDER 19 YEARS OF AGE TO USE ANY EBIKE AT ANY TIME;\\n\\n(iv)           YOU HAVE THE LEGAL AND MENTAL CAPACITY TO ENTER INTO THIS AGREEMENT;\\n\\n(v)            YOU HAVE ENSURED THAT EACH ADDITIONAL USER WHO IS UNDER 19 YEARS OF AGE HAS READ AND UNDERSTOOD THIS AGREEMENT AND THAT, IF NECESSARY, YOU HAVE EXPLAINED THE TERMS OF THIS AGREEMENT TO SUCH ADDITIONAL USER(S);\\n\\n(vi)           YOU ARE AGREEING TO THIS AGREEMENT (INCLUDING, WITHOUT LIMITATION, SECTION 3 (RESTRICTIONS AND OTHER TERMS AND CONDITIONS OF BIKE USE), SECTION 5 (RELEASE AND LIMITATION OF LIABILITY), SECTION 6 (ASSUMPTIONS OF RISKS DISCLAIMER) AND SECTION 8 (INDEMNIFICATION) ON BEHALF OF EACH SUCH ADDITIONAL USER;\\n\\n(vii)         YOU AUTHORIZE THE USE OF YOUR ACCOUNT FOR BIKE RENTAL SERVICES BY EACH SUCH ADDITIONAL USER IN ACCORDANCE WITH THIS AGREEMENT, INCLUDING THE RESTRICTIONS AND OTHER TERMS AND CONDITIONS OF BIKE USE OUTLINED FOR RIDERS IN SECTION 3 WHICH APPLY TO EACH ADDITIONAL USER; AND\\n\\n(viii)        YOU ARE RESPONSIBLE FOR EACH ADDITIONAL USER’S COMPLIANCE WITH ALL APPLICABLE PROVISIONS OF THIS AGREEMENT.\\n\\n2.17        RIDERS AGED 12 TO 18.  A parent or legal guardian of a Rider that is at least twelve (12) years old but less than nineteen (19) years old (a “**Youth Rider**” for the purposes of this Section 2.17), may purchase a Pass to only use a Classic Bike (i.e., not an Ebike) for the Youth Rider, but by purchasing a Pass for such a Youth Rider, the parent or legal guardian is hereby responsible for all the duties and responsibilities set out in this Agreement of such Youth Rider. \\n\\nIn addition, THE PARENT OR LEGAL GUARDIAN HEREBY AFFIRMS THAT:\\n\\n(i)             YOU ARE THE PARENT OR LEGAL GUARDIAN OF THE YOUTH RIDER;\\n\\n(ii)            YOU ARE AT LEAST 19 YEARS OF AGE AND THE YOUTH RIDER IS AT LEAST 150 CM IN HEIGHT;\\n\\n(iii)           YOU HAVE THE LEGAL AND MENTAL CAPACITY TO ENTER INTO THIS AGREEMENT;\\n\\n(iv)           YOU HAVE ENSURED THAT THE YOUTH RIDER HAS READ AND UNDERSTOOD THIS AGREEMENT AND THAT, IF NECESSARY, YOU HAVE EXPLAINED THE TERMS OF THIS AGREEMENT TO SUCH YOUTH RIDER;\\n\\n(v)            YOU ARE AGREEING TO THIS AGREEMENT (INCLUDING, WITHOUT LIMITATION, SECTION 3 (RESTRICTIONS AND OTHER TERMS AND CONDITIONS OF BIKE USE), SECTION 5 (RELEASE AND LIMITATION OF LIABILITY), SECTION 6 (ASSUMPTIONS OF RISKS DISCLAIMER) AND SECTION 8 (INDEMNIFICATION) ON BEHALF OF THE YOUTH RIDER;\\n\\n(vi)           YOU AUTHORIZE THE USE OF YOUR ACCOUNT FOR BIKE RENTAL SERVICES BY THE YOUTH RIDER IN ACCORDANCE WITH THIS AGREEMENT, INCLUDING THE RESTRICTIONS AND OTHER TERMS AND CONDITIONS OF BIKE USE OUTLINED FOR RIDERS IN SECTION 2.16 WHICH APPLY TO EACH YOUTH RIDER;\\n\\n(vii)         YOU WILL NOT PERMIT, AND WILL ENSURE THAT THE YOUTH RIDER DOES NOT, USE AN EBIKE AT ANY TIME; AND\\n\\n(viii)        YOU ARE RESPONSIBLE FOR THE YOUTH RIDER’S COMPLIANCE WITH ALL APPLICABLE PROVISIONS OF THIS AGREEMENT.\\n\\n2.18        CANCELLATION AND REFUNDS.  To cancel your membership, login to your Account at [www.mobibikes.ca or](http://www.mobibikes.ca.or/) on the Operator mobile app. If you cancel your membership, your Account will be maintained. To disable your Account, contact us at info@mobibikes.ca. When your Account is disabled, you can no longer access your Account. Operator offers refunds under limited circumstances. Please see the refund policy at &lt;https://www.mobibikes.ca/en/refund-policy&gt;.\\n\\n2.19        NON-TRANSFERABLE.  Except to the extent provided in Section 2.14, Memberships are non-transferable and cannot be shared, and rental of Bikes is restricted to the Account holder.\\n\\n2.20        ACCOUNT SUSPENSIONS.  The Operator reserves the right to suspend or cancel your Account without notice if you breach any provision of this Agreement. If your Account is suspended, you may be charged a reinstatement fee of up to $25 to reactivate your Account once a resolution in respect of the breach has been reached to the satisfaction of the Operator.\\n\\n2.21        STOPOVER USAGE.  See Section 1.3(d) on the purpose and proper usage of Stopover. A Bike in Stopover is considered an active ride, and therefore, contributing to the overall Trip time included in your Pass or Membership. You are liable for all Claims for Bikes engaged in Stopover on your Account. To reduce liability for any fees resulting from a lost or stolen Bike while in Stopover, it is highly recommended to document the proper use of Stopover by taking a photo or video each time you engage Stopover and promptly sending such documentation to the Operator if the Bike becomes lost or stolen.\\n\\n3.              RESTRICTIONS AND OTHER TERMS AND CONDITIONS OF BIKE USE.\\n\\n3.1           REPRESENTATIONS AND WARRANTIES.  As a condition precedent to the Operator’s agreement to allow you to participate in the Bike Share Program and to rent a Bike, you represent and warrant to the Operator that:\\n\\n(a)            You are at least twelve (12) years of age if using or renting a Classic Bike, and at least nineteen (19) years of age if using or renting an Ebike;\\n\\n(b)            You (or your parent or legal guardian if Section 2.17 applies) are the legal holder of and named on the Credit Card used to rent a Bike in accordance with the terms of this Agreement;\\n\\n(c)            You are experienced and familiar with the safe and competent operation of the Bike, and you are physically and mentally fit to ride the Bike;\\n\\n(d)            You are familiar with all applicable rules, regulations, codes and laws that relate to the safe and legal operation of a bicycle; and\\n\\n(e)            You will wear a helmet at all times that you are in motion on the Bike.\\n\\n3.2           ACKNOWLEDGEMENTS AND AGREEMENTS.  As a condition precedent to the Operator’s agreement to allow you to participate in the Bike Share Program and to rent a Bike, you acknowledge and agrees as follows:\\n\\n(a)            You are fully aware that riding a bicycle on streets poses a risk of accident due to motorists, pedestrians, and road conditions, and you must be aware and keep a proper lookout to avoid such accidents;\\n\\n(b)            You are fully trained and capable of operating and riding a bicycle and are not relying in any way on the Operator to learn how to operate or ride a bicycle;\\n\\n(c)            Failure to use a helmet or to use the Bike in a careful and reasonably competent manner may result in bodily injury or death to you and others, for which you accept full responsibility;\\n\\n(d)            You are solely responsible for obtaining and using a helmet and proper clothing and shoes;\\n\\n(e)            You are required to wear a helmet pursuant to the law of the Province of British Columbia;\\n\\n(f)             A helmet, even when used, does not eliminate the risk of bodily injury in the event of an accident;\\n\\n(g)            You are solely responsible for operating and riding a Bike in a careful and reasonably competent manner;\\n\\n(h)            All Bikes are and shall remain the exclusive property of the Operator at all times;\\n\\n(i)             You are solely responsible for any moving violations and fines incurred by you while using the Bike, including any fees for parking the Bike in prohibited locations or for riding without wearing a helmet;\\n\\n(j)             The Operator is not obligated to provide insurance of any kind related to you or your use of the Bike, and in the event that the Operator, at its option, carries insurance, you shall remain liable for any liability, property damage, personal injury, injury to others, damages, penalties, fines, losses, and expenses of any kind whatsoever;\\n\\n(k)            If you cause any damage to property or injury to another party while operating or in possession of the Bike, you are solely liable for all such damage or injury;\\n\\n(l)             You shall return the Bike to the Operator in the same condition as when received;\\n\\n(m)          You are liable for any and all damages resulting from improper use or abuse of the Bike and the full cost of such damages; and\\n\\n(n)            The Operator provides Bikes as a service, and such rental availability is intended to be used only by those persons who are able and qualified to operate a Bike on their own and who have agreed to all terms and conditions of this Agreement.\\n\\n3.3           REQUIREMENTS.  As a condition precedent to the Operator’s agreement to allow you to participate in the Bike Share Program and to rent a Bike, you shall:\\n\\n(a)            put on a helmet and make sure it is fit properly to your head;\\n\\n(b)            carefully inspect the Bike that you wish to rent prior to use to ensure the Bike is in good operating condition;\\n\\n(c)            make sure the Lock is stored properly inside the handlebar during Bike use, and is used to lock the Bike whenever the Bike is not in use when away from Stations;\\n\\n(d)            test the Bike’s operating components before proceeding with the intended use, including, but not limited to the brakes, tires, gears, pedals, lights, frame and saddle;\\n\\n(e)            promptly notify the Operator customer service of any defect, malfunction or needed repair to a Bike;\\n\\n(f)             adjust the Bike saddle to proper height prior to operating the Bike;\\n\\n(g)            adjust Bike riding behavior for safe operation according to weather conditions;\\n\\n(h)            only use Bike riding behavior that is that of a reasonably experienced and prudent bicycle rider;\\n\\n(i)             stop riding and return the Bike to Station if the Bike is not functioning properly; and\\n\\n(j)             contact the Operator and local police immediately in the event of theft of the Bike or an accident that occurs during your use of the Bike resulting in bodily injury,\\n\\n(collectively, the “**Use Requirements**”).\\n\\n3.4           RESTRICTED USES.  You shall not do any of the following at any time:\\n\\n(a)            use any Bike if you are not wearing a helmet;\\n\\n(b)            allow anyone who is younger than 19 years of age to use a Bike, except in accordance with Section 2.14 or 2.17;\\n\\n(c)            use any Bike if you have any existing physical or mental condition that would prevent you from safely operating the Bike;\\n\\n(d)            operate a Bike while carrying any item that impedes your ability to safely operate the Bike;\\n\\n(e)            operate a Bike while under the influence of alcohol, drugs, or any other substance that impairs your ability to safely operate the Bike;\\n\\n(f)             use any cell phone or electronic device, including, but not limited to, for the purposes of phone calls, text messages, music or any other use that distracts you, or has the potential to distract you, from the safe operation of the Bike;\\n\\n(g)            allow any other person to use the Bike at the same time as yourself, or allow more than one person to be carried on the Bike at any time;\\n\\n(h)            overfill the Bike basket or place objects weighing in total more 9 kilograms (20 pounds) in the Bike basket;\\n\\n(i)             violate any applicable law or legal requirement while using a Bike;\\n\\n(j)             operate or use a Bike in any manner during adverse weather conditions, including but not limited to: hail, snow, dust storms, fog, heavy rains, or lightning storms;\\n\\n(k)            ride or operate a Bike that has any defect, fails to operate as a properly functioning bicycle, or that is in need of repair;\\n\\n(l)             continue using the Bike if it, or any component of it, should become defective or malfunction;\\n\\n(m)          use the Bike for racing (two or more riders competing to arrive at a particular location first), trick riding, jumping, stunt riding and/or, off-road riding;\\n\\n(n)            use the Bike for any commercial purposes;\\n\\n(o)            tow, pull, carry or push any person or object with a Bike;\\n\\n(p)            remove, modify, or add any accessories, parts or components of any Bike;\\n\\n(q)            ride the Bike without paying applicable user fee at the time they become due; and\\n\\n(r)             use an Ebike, or permit any other individuals from using an Ebike, if under the age of 19,\\n\\n(each a “**Restricted Use**”).\\n\\n3.5           LOST AND FOUND POLICY. The Operator is not responsible for loss of or damage to a Rider’s property or the property of others left at any time in or on any Bike or on the Operator’s premises, even if it is in the Operator’s possession and regardless of who is at fault. The Operator is not obligated to contact a Rider regarding lost items belonging to the Rider, other authorized user(s), or any other person. The Operator is not obligated to remove a Bike from service due to loss of property and is not required to search any Bike for lost property.\\n\\n3.6           LIMITED USE.  The Operator may limit your Account to the use of Classic Bikes only (i.e., no right to use Ebikes) if the Operator determines, in its sole discretion, that you have breached any provision of this Agreement, including repeat system abuse, or if a Bike rented under your Account has been lost or stolen, or has been deemed lost or stolen in accordance with this Agreement.\\n\\n4.              SERVICE LIMITATIONS.\\n\\n4.1           The Rider acknowledges and agrees that from and after the date that the Operator makes Bikes available to the public for rental, the Operator may, in its sole discretion: suspend all or part of its Bike Share Program at any time; relocate Stations; reduce the number of Bikes available for rent; and otherwise operate its Bike rental program in its sole discretion.\\n\\n4.2           The Rider further acknowledges that the Operator may suspend the availability of Bikes during adverse weather conditions, or may be required to suspend the rental of Bikes by the city or applicable jurisdiction in which the Bikes are located.\\n\\n4.3           The Rider shall not be entitled to a refund of any fees for unused rental periods unless the Operator’s Bike rental service shall have been suspended for a total of more than fifteen (15) days over the course of a twelve (12) month period.\\n\\n4.4           The Rider acknowledges, understands and agrees that Operator does not represent or warrant that Bikes will be available for rental at any Station at any time.\\n\\n4.5           The Operator may, in its sole discretion, require the return of any or all of its Bikes at any time.\\n\\n5.              RELEASE AND LIMITATION OF LIABILITY.\\n\\n5.1           FOR AND IN CONSIDERATION OF RENTAL AND USE OF THE BIKE, THE RIDER, FOR HIMSELF OR HERSELF AND ON BEHALF OF RIDER’S HEIRS, EXECUTORS, ADMINISTRATORS AND ASSIGNS, FOREVER RELEASES AND RELINQUISHES AND DISCHARGES (i) THE OPERATOR AND THE OPERATOR’S OFFICERS, BOARDS AND COMMISSIONS, MEMBERS, MANAGERS, EMPLOYEES, SUPPLIERS, AGENTS, REPRESENTATIVES, (ii) ANY MUNICIPALITY OR OTHER AUTHORITY WITH WHICH THE OPERATOR HAS CONTRACTED WITH TO PROVIDE A BIKE SHARE PROGRAM, AND (iii) ANY OWNER OF PROPERTY WITH WHICH THE OPERATOR, CITY OR OTHER APPLICABLE AUTHORITY HAS CONTRACTED WITH TO PROVIDE REAL PROPERTY ON WHICH A BIKE SHARE FACILITY, INCLUDING, WITHOUT LIMITATION, STATIONS, HUBS, RACKS, INTENDED FOR BIKE SHARE USE (ALL, COLLECTIVELY, THE “**OPERATOR PARTIES**”) FROM ANY AND ALL CLAIMS, DEMANDS, DISPUTES, LOSSES, LIABILITIES, DEBTS, LIENS, CHARGES, PENALTIES, PROCEEDINGS, CAUSES OF ACTION AND DAMAGES INCLUDING FOR PERSONAL INJURY, WRONGFUL DEATH, PROPERTY DAMAGE, AND INJURY TO RIDER OR TO THIRD PARTIES (COLLECTIVELY, “**CLAIMS**”), INCLUDING UNKNOWN OR UNANTICIPATED CLAIMS, WHICH ARISE FROM OR ARE RELATED DIRECTLY OR INDIRECTLY TO THIS AGREEMENT OR THE RENTAL, MAINTENANCE, DESIGN, USE AND/OR OPERATION OF THE OPERATOR EQUIPMENT, INCLUDING THE BIKES, OR THE OPERATOR WEBSITE, INCLUDING ANY AND ALL CLAIMS RELATED TO THE SOLE OR PARTIAL NEGLIGENCE OF OPERATOR, THE OPERATOR PARTIES OR ANY OTHER PARTY. THE RIDER HEREBY EXPRESSLY WAIVES ANY CLAIMS AGAINST THE OPERATOR PARTIES WHICH THE RIDER DOES NOT KNOW OR SUSPECT TO EXIST IN HIS OR HER FAVOR AT THE TIME OF RENTING A BIKE, AND EXPRESSLY WAIVES ALL OF THE RIDER'S RIGHTS UNDER ANY STATUTES THAT PURPORT TO PRESERVE THE RIDER'S UNKNOWN CLAIMS.\\n\\n5.2           IF THE OPERATOR OR THE OPERATOR PARTIES ARE DEEMED TO HAVE ANY LIABILITY UNDER THIS AGREEMENT OR ARISING OUT OF A RIDER’S USE OF THE OPERATOR EQUIPMENT, INCLUDING THE BIKES, OR THE OPERATOR WEBSITE, SUCH LIABILITY SHALL NOT EXCEED THE AMOUNT OF THE MEMBERSHIP OR RENTAL PAID TO THE OPERATOR BY THE RIDER IN THE TWELVE (12) MONTHS PRECEDING THE DATE OF THE EVENT GIVING RISE TO SUCH LIABILITY.\\n\\n6.              ASSUMPTIONS OF RISKS; DISCLAIMER.\\n\\n6.1           THE RIDER EXPRESSLY ACKNOWLEDGES AND ACCEPTS THAT THE RIDER’S RENTAL AND USE OF THE BIKE IS AT HIS/HER OWN RISK. THE RIDER ACCEPTS THE BIKE FOR USE AFTER EXERCISING HIS/HER OWN FREE CHOICE TO PARTICIPATE VOLUNTARILY IN THIS ACTIVITY AND AFTER HAVING INSPECTED THE BIKE AND CERTIFYING THAT IS IN GOOD OPERATING CONDITION. THE RIDER UNDERSTANDS THAT BICYCLING MAY BE A HAZARDOUS ACTIVITY. THE RIDER ACKNOWLEDGES, UNDERSTANDS AND ASSUMES ALL RISK RELATING TO THE RENTAL, MAINTENANCE, DESIGN, USE AND/OR OPERATION OF THE OPERATOR EQUIPMENT, INCLUDING THE BIKES, AND THE OPERATOR WEBSITE AND UNDERSTANDS THAT BICYCLING INVOLVES RISK TO THE RIDER AND OTHERS INCLUDING DAMAGES, BODILY INJURY, PARTIAL OR TOTAL DISABILITY, PARALYSIS AND DEATH TO THE RIDER OR OTHERS, AND THAT THE RIDER HAS FULL KNOWLEDGE OF SAID RISKS AND DANGERS, INCLUDING SUCH RISKS, DAMAGES AND INJURIES THAT MAY ARISE FROM THE NEGLIGENCE OF OTHERS OR AS A RESULT OF ROADWAY CONDITIONS. ALL BIKES AND OTHER OPERATOR EQUIPMENT ARE PROVIDED “AS IS” AND WITHOUT ANY WARRANTY OF ANY KIND, WHETHER EXPRESS OR IMPLIED, WRITTEN OR ORAL, INCLUDING, WITHOUT LIMITATION, ANY WARRANTY OF MERCHANTABILITY, QUALITY OR FITNESS FOR A PARTICULAR PURPOSE. OPERATOR AND THE OPERATOR PARTIES HEREBY DISCLAIM ANY CLAIM IN TORT (INCLUDING NEGLIGENCE, PRODUCT LIABILITY OR STRICT LIABILITY).\\n\\n6.2           IN NO EVENT WILL THE RIDER CLAIM THAT THE OPERATOR, OR ANY OF THE OPERATOR PARTIES INDIVIDUALLY OR COLLECTIVELY, FAILED TO ADEQUATELY TRAIN THE RIDER, OR PROVIDE THE RIDER WITH ADEQUATE INSTRUCTIONS NECESSARY TO RIDE THE BIKE IN THE SAME MANNER AS A PERSON WHO IS AN EXPERIENCED BICYCLE RIDER WHO HAS BEEN TRAINED TO RIDE A BICYCLE IN A SAFE AND CAREFUL MANNER.\\n\\n7.              DISPUTE RESOLUTION.\\n\\n7.1           The Rider agrees that the Operator, at its sole discretion, may submit any disputes whatsoever arising out of, resulting from, and/or relating to this Agreement, the Rider’s use of the Operator’s Equipment, including, without limitation, Bikes, and/or the Operator website, to final and binding arbitration under the rules of procedure of the British Columbia International Commercial Arbitration Centre by one or more arbitrators appointed in accordance with the said rules. In the event that the Operator submits such dispute to arbitration, then such arbitration shall be mandatory and binding on the parties. Such proceedings shall be held in the City of Vancouver. All arbitration proceedings will be conducted in the English language.\\n\\n7.2           SHOULD THE OPERATOR NOT ELECT TO SUBMIT ANY DISPUTE OR CLAIM TO ARBITRATION, TO THE MAXIMUM EXTENT PERMITTED BY LAW, THE OPERATOR AND THE RIDER EACH WAIVE ANY RIGHT TO TRIAL BY JURY IN ANY LITIGATION OR TO HAVE A JURY PARTICIPATE IN RESOLVING ANY DISPUTE ARISING OUT OF OR WITH RESPECT TO THIS AGREEMENT OR THE RIDER’S USE OF THE OPERATOR’S EQUIPMENT, INCLUDING, WITHOUT LIMITATION, BIKES, AND/OR THE OPERATOR WEBSITE.\\n\\n8.              INDEMNIFICATION.\\n\\n8.1           The Rider shall indemnify, defend and hold harmless the Operator, the Operator Parties and the City of Vancouver for, from and against any and all Claims related to or arising out of this Agreement, including, but not limited to the Rider’s breach of any representations, warranties or covenants set forth in this Agreement, and the rental, maintenance, design, use or operation of the Bike, the Locks, the Stations and/or the Operator website, even where caused in whole or in part by the Operator’s negligence, and/or the negligence of others, whether presently known or unknown. At the Operator’s option, the Rider will assume control of the defense and settlement of any Claim subject to indemnification by the Rider (provided that, in such event, the Operator may at any time elect to take over control of the defense and settlement of any such Claim). In no event may the Rider settle any Claim without the Operator’s prior written consent.\\n\\n9.              TERMINATION OF AGREEMENT.\\n\\n9.1           The Rider acknowledges, understands and agrees that the Rider’s use of the Bike Share Program is “at the will” of the Operator, and that the Operator may terminate this Agreement at any time and cancel the Rider’s Account, without cause, legal process, or notice to the Rider. The Rider waives all claims, causes of actions, expenses, and/or damages connected and/or related to any such termination. The Rider shall not be entitled to a refund of any amount paid for unused rental periods if this Agreement is terminated for cause.\\n\\n9.2           The Rider may terminate the Rider’s rental plan at any time; provided, however, that no refund will be provided by the Operator for time already used or not used by the Rider.\\n\\n10.           FEE SCHEDULE.\\n\\n10.1        OVERAGE FEES AND PENALTIES.\\n\\n|  |  |  |\\n| --- | --- | --- |\\n|  | **Community**  **Pass Holder** | **General** |\\n| Overage Fees  Fees incurred when the Rider goes over the allotted ride time of their plan. | Classic Bike: $0.25 /min  Ebike: $0.35 /min | Classic Bike: $0.29 /min  Ebike: $0.19 /min |\\n| Late Return  Fee charged when a Bike notifies of a lock error and is left active at a station. | Classic Bike: $5  Ebike: $15 | Classic Bike: $15  Ebike: $30 |\\n| Loss of Use  Rate charged if a Bike is lost, stolen or forced out of use due to damage. Charged after the Bike is found. | Classic Bike: $5 /Day  Ebike: $15 /Day |\\n| Reinstatement Fee  Cost to reinstate membership after a Bike is reported missing or after an account has been suspended | $20 | $25 |\\n| Replacement Fee  Mobi reserves the right to charge up to the full cost of replacing equipment | Classic Bike: $2,000  Ebike: $4,000 |\\n\\n10.2        RECOVERY, CLEANING AND DAMAGE FEES.\\n\\n|  |  |\\n| --- | --- |\\n| Pick up &amp; Recovery (within service area)  Cost of recovering, inspecting and rebalancing a Bike within Mobi’s service area (includes VPD pick-ups) | Up to $50 |\\n| Pick up &amp; Recovery (outside of service area)  Cost of recovering, inspecting and rebalancing a Bike outside of Mobi’s service area | Up to $80 |\\n| Excessive cleaning fee  Extra cleaning required when a Bike is returned unusable due to uncleanliness | Up to $80 |\\n| Minor damage repair  If a Bike is damaged during your Rental Period of the Bike, beyond regular wear and tear, you shall be charged a fee that is equal to the cost of repairing such damage.  Ex. - Switching lights, saddle replacement, small graffiti | Up to $100 |\\n| Major damage repair  If a Bike is damaged during your Rental Period of the Bike, beyond regular wear and tear, you shall be charged a fee that is equal to the cost of repairing such damage.  Ex. - Full resticker, large graffiti, broken frame, wheels, forks, etc. | Up to the replacement fee |\\n\\n11.           GENERAL PROVISIONS\\n\\n11.1        ASSIGNMENT. The Operator may assign its rights and duties under this Agreement in its sole discretion to any party at any time without notice to the Rider.\\n\\n11.2        NO WAIVER. The Operator’s failure to insist upon or enforce strict performance of any provision of this Agreement shall not be construed as a waiver of any provision or right. Neither the course of conduct between the parties nor trade practice shall act to modify any part of this Agreement. No waiver by the Operator shall be construed as a waiver of any preceding or succeeding breach of any provision in this Agreement.\\n\\n11.3        SEVERABILITY. If any provision of this Agreement is held by a court of competent jurisdiction to be contrary to law, the remaining provisions of the Agreement shall remain in full force and effect.\\n\\n11.4        SURVIVAL. All provisions of this Agreement relating to limitation and exclusion of liability, waivers, assumption of risk, warranties and indemnification obligations shall survive the termination of this Agreement, and all amounts unpaid at the time of termination or expiration of this Agreement shall remain due and payable.\\n\\n11.5        REFUND POLICY. Rider may access Operator’s refund policy at: &lt;https://www.mobibikes.ca/en/refund-policy&gt;.\\n\\n11.6        PRIVACY POLICY. Rider may access Operator’s privacy policy applicable to this Agreement at: &lt;https://www.mobibikes.ca/en/privacy-policy&gt;.\\n\\n11.7        ENTIRE AGREEMENT. This Agreement constitutes the final and entire Agreement between the Operator and the Rider and prevails over any prior or contemporaneous, conflicting or additional communications and agreements that pertain to the matter of this Agreement, unless otherwise agreed to by the Parties in writing. The Operator shall have the right to revise, change and modify the terms and conditions contained in this Agreement at any time without prior written notification by posting the revised Agreement on [www.mobibikes.ca](http://www.vancouverbikeshare.ca/), and such changes shall apply to all future use of Bikes after the date of such changes. Riders shall be solely responsible for reviewing and becoming familiar with any modification to this Agreement. Use and/or operation of the Bike by the Rider following any modifications to this Agreement constitutes the Rider’s acceptance of the terms and conditions as modified.</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>http://www.mobibikes.ca/en/local-bike-shops</td>\n",
       "      <td>Local Bike shops - Mobi by Rogers</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2025-11-13 02:12:17.479851</td>\n",
       "      <td>success</td>\n",
       "      <td># Local Bike shops - Mobi by Rogers\\n\\n**URL:** http://www.mobibikes.ca/en/local-bike-shops\\n**Description:** \\n**Main Heading:** \\n**Scraped:** 2025-11-13 02:12:17\\n\\n---\\n\\nRiding with a family?  Riding for more than an hour?  If yes, we encourage you to visit one of our many bike rental locations listed below. [Search for bike rentals in Vancouver on google.](https://www.google.ca/webhp?sourceid=chrome-instant&amp;ion=1&amp;espv=2&amp;ie=UTF-8#q=local%20bike%20rentals)\\n\\n### **Vancouver Bike Rentals**\\n\\n**Bayshore Bicycle Rentals**\\n\\n745 Denman St\\n\\n604 688-2453\\n\\n**Bike Doctor**\\n\\n137 W Broadway\\n\\n604 873-2453\\n\\n**Bicycles Sports Pacific**  \\n999 Pacific Street  \\n604 682 4537  \\n  \\n1387 Hornby Street  \\n604 682 4537  \\n  \\n**Bikes N' Blades Rental**\\n\\n718 Denman St\\n\\n604 602-9899\\n\\n**Bike Rental**\\n\\n708 Denman St\\n\\n**Bikes for All**\\n\\n112 E 7th Avenue\\n\\n604 872-4534\\n\\n**Bikes on Robson**\\n\\n1531 Robson St\\n\\n778 371-7316\\n\\n**Cycle BC Rentals + Tours**\\n\\n73 E 6th Avenue\\n\\n604 709-5663\\n\\n**Cycle City Tours and Rentals**\\n\\n1344 Burrard St\\n\\n604 618-8626\\n\\n**Cycle City Tours and Rentals**\\n\\n648 Hornby St\\n\\n604 618-8626\\n\\n**English Bay Bike Rentals**\\n\\n1754 Davie St\\n\\n604 568-8490\\n\\n**EzeeRiders Seawall**\\n\\n1055 Canada Place\\n\\n604 331-1789\\n\\n**EzeeRiders on Robson**\\n\\n1823 Robson St\\n\\n604 331-1789              \\n  \\n**JV Bike**  \\n929 Expo Blvd  \\n  \\n**More bikes**  \\n1856 West 4th  \\nVancouver, BC  \\n778-379-9168\\n\\n**Reckless: Fir**\\n\\n1810 Fir St\\n\\n604 731-2420\\n\\n**Reckless: Davie**\\n\\n110 Davie St\\n\\n604 648-2600\\n\\n**Seawall Adventure Centre**\\n\\n1075 W Waterfront Rd\\n\\n604 233-3500\\n\\n**Simon's Bike Shop**\\n\\n608 Robson St\\n\\n604 602-1181\\n\\n**Spokes Bicycle Rental**\\n\\n1798 W Georgia St\\n\\n604 688-5141\\n\\n**Stanley Park Cycle**\\n\\n768 Denman St\\n\\n604 688-0087\\n\\n**Union Street Cycles**  \\n247 Union Street  \\n604 255 5097\\n\\n**Urban Waves**\\n\\n#210 510 Nicola St\\n\\n604 259-9526      \\n\\n**Vancouver Bike Tours**\\n\\n1754 Davie St\\n\\n778 628-4316    \\n\\n**Yes Cycle**\\n\\n687 Denman St\\n\\n604 569-0088\\n\\n**Zap Bike Rentals**\\n\\n1680 Robson St\\n\\n604 558-1680</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>http://www.mobibikes.ca/en/map</td>\n",
       "      <td>Find a bike - Mobi by Rogers</td>\n",
       "      <td>Find bikes and stations. Filter your search to find available bicycles or open docks using the toggle below.</td>\n",
       "      <td></td>\n",
       "      <td>2025-11-13 02:12:21.540403</td>\n",
       "      <td>success</td>\n",
       "      <td># Find a bike - Mobi by Rogers\\n\\n**URL:** http://www.mobibikes.ca/en/map\\n**Description:** Find bikes and stations. Filter your search to find available bicycles or open docks using the toggle below.\\n**Main Heading:** \\n**Scraped:** 2025-11-13 02:12:21\\n\\n---\\n\\nLoading...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "DataFrame[url: string, title: string, description: string, main_heading: string, scraped_at: timestamp, status: string, content_md: string, site_page_id: bigint]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show ten rows of the bronze_site table we already proudced\n",
    "\n",
    "display(spark.table(f\"`{CATALOG}`.`{SCHEMA}`.silver_site\").limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8503a0d9-6234-445b-8b6d-4709c95d1fd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"ts\": \"2025-11-12 19:45:36.675\", \"level\": \"ERROR\", \"logger\": \"pyspark.sql.connect.client.logging\", \"msg\": \"GRPC Error received\", \"context\": {}, \"exception\": {\"class\": \"_MultiThreadedRendezvous\", \"msg\": \"<_MultiThreadedRendezvous of RPC that terminated with:\\n\\tstatus = StatusCode.INTERNAL\\n\\tdetails = \\\"[TABLE_OR_VIEW_NOT_FOUND] The table or view `${CATALOG}`.`${SCHEMA}`.`silver_site` cannot be found. Verify the spelling and correctness of the schema and catalog.\\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 1 pos 12;\\n'SetTableProperties [delta.enableChangeDataFeed=true]\\n+- 'UnresolvedTable [${CATALOG}, ${SCHEMA}, silver_site], ALTER TABLE ... SET TBLPROPERTIES, true, true\\n\\\"\\n\\tdebug_error_string = \\\"UNKNOWN:Error received from peer  {grpc_message:\\\"[TABLE_OR_VIEW_NOT_FOUND] The table or view `${CATALOG}`.`${SCHEMA}`.`silver_site` cannot be found. Verify the spelling and correctness of the schema and catalog.\\\\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\\\\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 1 pos 12;\\\\n\\\\'SetTableProperties [delta.enableChangeDataFeed=true]\\\\n+- \\\\'UnresolvedTable [${CATALOG}, ${SCHEMA}, silver_site], ALTER TABLE ... SET TBLPROPERTIES, true, true\\\\n\\\", grpc_status:13}\\\"\\n>\", \"stacktrace\": [{\"class\": null, \"method\": \"_execute_and_fetch_as_iterator\", \"file\": \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py\", \"line\": \"1932\"}, {\"class\": null, \"method\": \"__next__\", \"file\": \"<frozen _collections_abc>\", \"line\": \"356\"}, {\"class\": null, \"method\": \"send\", \"file\": \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/reattach.py\", \"line\": \"141\"}, {\"class\": null, \"method\": \"_has_next\", \"file\": \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/reattach.py\", \"line\": \"202\"}, {\"class\": null, \"method\": \"_has_next\", \"file\": \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/reattach.py\", \"line\": \"174\"}, {\"class\": null, \"method\": \"_call_iter\", \"file\": \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/reattach.py\", \"line\": \"307\"}, {\"class\": null, \"method\": \"_call_iter\", \"file\": \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/reattach.py\", \"line\": \"279\"}, {\"class\": null, \"method\": \"<lambda>\", \"file\": \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/reattach.py\", \"line\": \"175\"}, {\"class\": null, \"method\": \"__iter__\", \"file\": \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py\", \"line\": \"658\"}, {\"class\": null, \"method\": \"__next__\", \"file\": \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"538\"}, {\"class\": null, \"method\": \"_next\", \"file\": \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"962\"}]}}\n",
      "{\"ts\": \"2025-11-12 19:45:36.675\", \"level\": \"ERROR\", \"logger\": \"pyspark.sql.connect.client.logging\", \"msg\": \"GRPC Error received\", \"context\": {}, \"exception\": {\"class\": \"_MultiThreadedRendezvous\", \"msg\": \"<_MultiThreadedRendezvous of RPC that terminated with:\\n\\tstatus = StatusCode.INTERNAL\\n\\tdetails = \\\"[TABLE_OR_VIEW_NOT_FOUND] The table or view `${CATALOG}`.`${SCHEMA}`.`silver_site` cannot be found. Verify the spelling and correctness of the schema and catalog.\\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 1 pos 12;\\n'SetTableProperties [delta.enableChangeDataFeed=true]\\n+- 'UnresolvedTable [${CATALOG}, ${SCHEMA}, silver_site], ALTER TABLE ... SET TBLPROPERTIES, true, true\\n\\\"\\n\\tdebug_error_string = \\\"UNKNOWN:Error received from peer  {grpc_message:\\\"[TABLE_OR_VIEW_NOT_FOUND] The table or view `${CATALOG}`.`${SCHEMA}`.`silver_site` cannot be found. Verify the spelling and correctness of the schema and catalog.\\\\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\\\\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 1 pos 12;\\\\n\\\\'SetTableProperties [delta.enableChangeDataFeed=true]\\\\n+- \\\\'UnresolvedTable [${CATALOG}, ${SCHEMA}, silver_site], ALTER TABLE ... SET TBLPROPERTIES, true, true\\\\n\\\", grpc_status:13}\\\"\\n>\", \"stacktrace\": [{\"class\": null, \"method\": \"_execute_and_fetch_as_iterator\", \"file\": \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py\", \"line\": \"1932\"}, {\"class\": null, \"method\": \"__next__\", \"file\": \"<frozen _collections_abc>\", \"line\": \"356\"}, {\"class\": null, \"method\": \"send\", \"file\": \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/reattach.py\", \"line\": \"141\"}, {\"class\": null, \"method\": \"_has_next\", \"file\": \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/reattach.py\", \"line\": \"202\"}, {\"class\": null, \"method\": \"_has_next\", \"file\": \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/reattach.py\", \"line\": \"174\"}, {\"class\": null, \"method\": \"_call_iter\", \"file\": \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/reattach.py\", \"line\": \"307\"}, {\"class\": null, \"method\": \"_call_iter\", \"file\": \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/reattach.py\", \"line\": \"279\"}, {\"class\": null, \"method\": \"<lambda>\", \"file\": \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/reattach.py\", \"line\": \"175\"}, {\"class\": null, \"method\": \"__iter__\", \"file\": \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py\", \"line\": \"658\"}, {\"class\": null, \"method\": \"__next__\", \"file\": \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"538\"}, {\"class\": null, \"method\": \"_next\", \"file\": \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"962\"}]}}\n",
      "ERROR:pyspark.sql.connect.client.logging:GRPC Error received\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py\", line 1932, in _execute_and_fetch_as_iterator\n",
      "    for b in generator:\n",
      "             ^^^^^^^^^\n",
      "  File \"<frozen _collections_abc>\", line 356, in __next__\n",
      "  File \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/reattach.py\", line 141, in send\n",
      "    if not self._has_next():\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/reattach.py\", line 202, in _has_next\n",
      "    raise e\n",
      "  File \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/reattach.py\", line 174, in _has_next\n",
      "    self._current = self._call_iter(\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/reattach.py\", line 307, in _call_iter\n",
      "    raise e\n",
      "  File \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/reattach.py\", line 279, in _call_iter\n",
      "    return iter_fun()\n",
      "           ^^^^^^^^^^\n",
      "  File \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/reattach.py\", line 175, in <lambda>\n",
      "    lambda: next(self._iterator)  # type: ignore[arg-type]\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py\", line 658, in __iter__\n",
      "    for response in self._call:\n",
      "                    ^^^^^^^^^^\n",
      "  File \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/grpc/_channel.py\", line 538, in __next__\n",
      "    return self._next()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/grpc/_channel.py\", line 962, in _next\n",
      "    raise self\n",
      "grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:\n",
      "\tstatus = StatusCode.INTERNAL\n",
      "\tdetails = \"[TABLE_OR_VIEW_NOT_FOUND] The table or view `${CATALOG}`.`${SCHEMA}`.`silver_site` cannot be found. Verify the spelling and correctness of the schema and catalog.\n",
      "If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\n",
      "To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 1 pos 12;\n",
      "'SetTableProperties [delta.enableChangeDataFeed=true]\n",
      "+- 'UnresolvedTable [${CATALOG}, ${SCHEMA}, silver_site], ALTER TABLE ... SET TBLPROPERTIES, true, true\n",
      "\"\n",
      "\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"[TABLE_OR_VIEW_NOT_FOUND] The table or view `${CATALOG}`.`${SCHEMA}`.`silver_site` cannot be found. Verify the spelling and correctness of the schema and catalog.\\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 1 pos 12;\\n\\'SetTableProperties [delta.enableChangeDataFeed=true]\\n+- \\'UnresolvedTable [${CATALOG}, ${SCHEMA}, silver_site], ALTER TABLE ... SET TBLPROPERTIES, true, true\\n\", grpc_status:13}\"\n",
      ">\n",
      "{\"ts\": \"2025-11-12 19:45:37.079\", \"level\": \"ERROR\", \"logger\": \"SQLQueryContextLogger\", \"msg\": \"[TABLE_OR_VIEW_NOT_FOUND] The table or view `${CATALOG}`.`${SCHEMA}`.`silver_site` cannot be found. Verify the spelling and correctness of the schema and catalog.\\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 1 pos 12;\\n'SetTableProperties [delta.enableChangeDataFeed=true]\\n+- 'UnresolvedTable [${CATALOG}, ${SCHEMA}, silver_site], ALTER TABLE ... SET TBLPROPERTIES, true, true\\n\\n\\nJVM stacktrace:\\norg.apache.spark.sql.catalyst.ExtendedAnalysisException\\n\\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.tableNotFound(package.scala:94)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2(CheckAnalysis.scala:337)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2$adapted(CheckAnalysis.scala:324)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:312)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:311)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:311)\\n\\tat scala.collection.immutable.Vector.foreach(Vector.scala:2125)\\n\\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:311)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0(CheckAnalysis.scala:324)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0$(CheckAnalysis.scala:295)\\n\\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis0(Analyzer.scala:585)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:280)\\n\\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\\n\\tat com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:114)\\n\\tat com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:200)\\n\\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:105)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:266)\\n\\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:262)\\n\\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:585)\\n\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$resolveInFixedPoint$1(HybridAnalyzer.scala:439)\\n\\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\\n\\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:267)\\n\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:439)\\n\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:98)\\n\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:135)\\n\\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:91)\\n\\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$2(Analyzer.scala:642)\\n\\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:425)\\n\\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:642)\\n\\tat com.databricks.sql.unity.SAMSnapshotHelper$.visitPlansDuringAnalysis(SAMSnapshotHelper.scala:41)\\n\\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:634)\\n\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$3(QueryExecution.scala:347)\\n\\tat com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:114)\\n\\tat com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:200)\\n\\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:105)\\n\\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:697)\\n\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$8(QueryExecution.scala:832)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withExecutionPhase$1(SQLExecution.scala:158)\\n\\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:328)\\n\\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\\n\\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:324)\\n\\tat com.databricks.util.TracingSpanUtils$.$anonfun$withTracing$4(TracingSpanUtils.scala:235)\\n\\tat com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:129)\\n\\tat com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:233)\\n\\tat com.databricks.tracing.TracingUtils$.withTracing(TracingUtils.scala:296)\\n\\tat com.databricks.spark.util.DatabricksTracingHelper.withSpan(DatabricksSparkTracingHelper.scala:115)\\n\\tat com.databricks.spark.util.DBRTracing$.withSpan(DBRTracing.scala:47)\\n\\tat org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:139)\\n\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$7(QueryExecution.scala:832)\\n\\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1478)\\n\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$5(QueryExecution.scala:825)\\n\\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\\n\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$4(QueryExecution.scala:822)\\n\\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\\n\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$3(QueryExecution.scala:822)\\n\\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\\n\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:821)\\n\\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\\n\\tat org.apache.spark.sql.execution.QueryExecution.withQueryExecutionId(QueryExecution.scala:809)\\n\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:820)\\n\\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)\\n\\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:819)\\n\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:329)\\n\\tat com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:111)\\n\\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:328)\\n\\tat scala.util.Try$.apply(Try.scala:217)\\n\\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1687)\\n\\tat org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:60)\\n\\tat org.apache.spark.util.LazyTry.tryT(LazyTry.scala:59)\\n\\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:75)\\n\\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:389)\\n\\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:302)\\n\\tat org.apache.spark.sql.classic.Dataset$.$anonfun$ofRows$3(Dataset.scala:154)\\n\\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)\\n\\tat org.apache.spark.sql.classic.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1077)\\n\\tat com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:114)\\n\\tat com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:200)\\n\\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:105)\\n\\tat org.apache.spark.sql.classic.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1077)\\n\\tat org.apache.spark.sql.classic.Dataset$.ofRows(Dataset.scala:146)\\n\\tat org.apache.spark.sql.classic.SparkSession.$anonfun$sql$5(SparkSession.scala:856)\\n\\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)\\n\\tat org.apache.spark.sql.classic.SparkSession.sql(SparkSession.scala:819)\\n\\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.executeSQL(SparkConnectPlanner.scala:3587)\\n\\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleSqlCommand(SparkConnectPlanner.scala:3411)\\n\\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:3288)\\n\\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.handleCommand(ExecuteThreadRunner.scala:383)\\n\\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1748)\\n\\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:75)\\n\\tat org.apache.spark.sql.execution.QueryExecution.executedPlan(QueryExecution.scala:753)\\n\\tat com.databricks.spark.sqlgateway.history.SqlExecutionMetrics.$anonfun$setQueryExecution$1(SqlExecutionMetrics.scala:191)\\n\\tat scala.Option.flatMap(Option.scala:283)\\n\\tat com.databricks.spark.sqlgateway.history.SqlExecutionMetrics.setQueryExecution(SqlExecutionMetrics.scala:191)\\n\\tat com.databricks.spark.sqlgateway.history.SqlGatewayHistorySparkListener.$anonfun$onSqlStart$1(SqlGatewayHistorySparkListener.scala:831)\\n\\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\\n\\tat com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:114)\\n\\tat com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:200)\\n\\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:105)\\n\\tat com.databricks.spark.sqlgateway.history.SqlGatewayHistorySparkListener.com$databricks$spark$sqlgateway$history$SqlGatewayHistorySparkListener$$onSqlStart(SqlGatewayHistorySparkListener.scala:779)\\n\\tat com.databricks.spark.sqlgateway.history.SqlGatewayHistorySparkListener$$anonfun$onOtherEventDefault$1.applyOrElse(SqlGatewayHistorySparkListener.scala:249)\\n\\tat com.databricks.spark.sqlgateway.history.SqlGatewayHistorySparkListener$$anonfun$onOtherEventDefault$1.applyOrElse(SqlGatewayHistorySparkListener.scala:237)\\n\\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\\n\\tat com.databricks.spark.sqlgateway.history.utils.ScriptStatementHelper$$anonfun$onOtherEvent$1.applyOrElse(ScriptStatementHelper.scala:29)\\n\\tat com.databricks.spark.sqlgateway.history.utils.ScriptStatementHelper$$anonfun$onOtherEvent$1.applyOrElse(ScriptStatementHelper.scala:29)\\n\\tat scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:270)\\n\\tat com.databricks.spark.sqlgateway.history.SqlGatewayHistorySparkListener.$anonfun$onOtherEvent$1(SqlGatewayHistorySparkListener.scala:215)\\n\\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\\n\\tat com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:114)\\n\\tat com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:200)\\n\\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:105)\\n\\tat com.databricks.spark.sqlgateway.history.SqlGatewayHistorySparkListener.onOtherEvent(SqlGatewayHistorySparkListener.scala:215)\\n\\tat org.apache.spark.scheduler.SparkListenerBus.doPostEvent(SparkListenerBus.scala:108)\\n\\tat org.apache.spark.scheduler.SparkListenerBus.doPostEvent$(SparkListenerBus.scala:28)\\n\\tat org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:46)\\n\\tat org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:46)\\n\\tat org.apache.spark.util.ListenerBus.postToAll(ListenerBus.scala:208)\\n\\tat org.apache.spark.util.ListenerBus.postToAll$(ListenerBus.scala:172)\\n\\tat org.apache.spark.scheduler.AsyncEventQueue.super$postToAll(AsyncEventQueue.scala:150)\\n\\tat org.apache.spark.scheduler.AsyncEventQueue.$anonfun$dispatch$1(AsyncEventQueue.scala:150)\\n\\tat scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.scala:17)\\n\\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\\n\\tat org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:119)\\n\\tat org.apache.spark.scheduler.AsyncEventQueue$$anon$2.$anonfun$run$1(AsyncEventQueue.scala:115)\\n\\tat org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1575)\\n\\tat org.apache.spark.scheduler.AsyncEventQueue$$anon$2.run(AsyncEventQueue.scala:115)\", \"context\": {\"errorClass\": \"TABLE_OR_VIEW_NOT_FOUND\"}, \"exception\": {\"class\": \"_MultiThreadedRendezvous\", \"msg\": \"<_MultiThreadedRendezvous of RPC that terminated with:\\n\\tstatus = StatusCode.INTERNAL\\n\\tdetails = \\\"[TABLE_OR_VIEW_NOT_FOUND] The table or view `${CATALOG}`.`${SCHEMA}`.`silver_site` cannot be found. Verify the spelling and correctness of the schema and catalog.\\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 1 pos 12;\\n'SetTableProperties [delta.enableChangeDataFeed=true]\\n+- 'UnresolvedTable [${CATALOG}, ${SCHEMA}, silver_site], ALTER TABLE ... SET TBLPROPERTIES, true, true\\n\\\"\\n\\tdebug_error_string = \\\"UNKNOWN:Error received from peer  {grpc_message:\\\"[TABLE_OR_VIEW_NOT_FOUND] The table or view `${CATALOG}`.`${SCHEMA}`.`silver_site` cannot be found. Verify the spelling and correctness of the schema and catalog.\\\\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\\\\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 1 pos 12;\\\\n\\\\'SetTableProperties [delta.enableChangeDataFeed=true]\\\\n+- \\\\'UnresolvedTable [${CATALOG}, ${SCHEMA}, silver_site], ALTER TABLE ... SET TBLPROPERTIES, true, true\\\\n\\\", grpc_status:13}\\\"\\n>\", \"stacktrace\": [{\"class\": null, \"method\": \"_execute_and_fetch_as_iterator\", \"file\": \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py\", \"line\": \"1932\"}, {\"class\": null, \"method\": \"__next__\", \"file\": \"<frozen _collections_abc>\", \"line\": \"356\"}, {\"class\": null, \"method\": \"send\", \"file\": \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/reattach.py\", \"line\": \"141\"}, {\"class\": null, \"method\": \"_has_next\", \"file\": \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/reattach.py\", \"line\": \"202\"}, {\"class\": null, \"method\": \"_has_next\", \"file\": \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/reattach.py\", \"line\": \"174\"}, {\"class\": null, \"method\": \"_call_iter\", \"file\": \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/reattach.py\", \"line\": \"307\"}, {\"class\": null, \"method\": \"_call_iter\", \"file\": \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/reattach.py\", \"line\": \"279\"}, {\"class\": null, \"method\": \"<lambda>\", \"file\": \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/reattach.py\", \"line\": \"175\"}, {\"class\": null, \"method\": \"__iter__\", \"file\": \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py\", \"line\": \"658\"}, {\"class\": null, \"method\": \"__next__\", \"file\": \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"538\"}, {\"class\": null, \"method\": \"_next\", \"file\": \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/grpc/_channel.py\", \"line\": \"962\"}]}}\n",
      "ERROR:SQLQueryContextLogger:[TABLE_OR_VIEW_NOT_FOUND] The table or view `${CATALOG}`.`${SCHEMA}`.`silver_site` cannot be found. Verify the spelling and correctness of the schema and catalog.\n",
      "If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\n",
      "To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 1 pos 12;\n",
      "'SetTableProperties [delta.enableChangeDataFeed=true]\n",
      "+- 'UnresolvedTable [${CATALOG}, ${SCHEMA}, silver_site], ALTER TABLE ... SET TBLPROPERTIES, true, true\n",
      "\n",
      "\n",
      "JVM stacktrace:\n",
      "org.apache.spark.sql.catalyst.ExtendedAnalysisException\n",
      "\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.tableNotFound(package.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2(CheckAnalysis.scala:337)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2$adapted(CheckAnalysis.scala:324)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:312)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:311)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:311)\n",
      "\tat scala.collection.immutable.Vector.foreach(Vector.scala:2125)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:311)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0(CheckAnalysis.scala:324)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0$(CheckAnalysis.scala:295)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis0(Analyzer.scala:585)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:280)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:114)\n",
      "\tat com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:200)\n",
      "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:105)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:266)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:262)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:585)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$resolveInFixedPoint$1(HybridAnalyzer.scala:439)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:439)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:98)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:135)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:91)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$2(Analyzer.scala:642)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:425)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:642)\n",
      "\tat com.databricks.sql.unity.SAMSnapshotHelper$.visitPlansDuringAnalysis(SAMSnapshotHelper.scala:41)\n",
      "\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:634)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$3(QueryExecution.scala:347)\n",
      "\tat com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:114)\n",
      "\tat com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:200)\n",
      "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:105)\n",
      "\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:697)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$8(QueryExecution.scala:832)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withExecutionPhase$1(SQLExecution.scala:158)\n",
      "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:328)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\n",
      "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:324)\n",
      "\tat com.databricks.util.TracingSpanUtils$.$anonfun$withTracing$4(TracingSpanUtils.scala:235)\n",
      "\tat com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:129)\n",
      "\tat com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:233)\n",
      "\tat com.databricks.tracing.TracingUtils$.withTracing(TracingUtils.scala:296)\n",
      "\tat com.databricks.spark.util.DatabricksTracingHelper.withSpan(DatabricksSparkTracingHelper.scala:115)\n",
      "\tat com.databricks.spark.util.DBRTracing$.withSpan(DBRTracing.scala:47)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:139)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$7(QueryExecution.scala:832)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1478)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$5(QueryExecution.scala:825)\n",
      "\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$4(QueryExecution.scala:822)\n",
      "\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$3(QueryExecution.scala:822)\n",
      "\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:821)\n",
      "\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.withQueryExecutionId(QueryExecution.scala:809)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:820)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:819)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:329)\n",
      "\tat com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:111)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:328)\n",
      "\tat scala.util.Try$.apply(Try.scala:217)\n",
      "\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1687)\n",
      "\tat org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:60)\n",
      "\tat org.apache.spark.util.LazyTry.tryT(LazyTry.scala:59)\n",
      "\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:75)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:389)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:302)\n",
      "\tat org.apache.spark.sql.classic.Dataset$.$anonfun$ofRows$3(Dataset.scala:154)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)\n",
      "\tat org.apache.spark.sql.classic.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1077)\n",
      "\tat com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:114)\n",
      "\tat com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:200)\n",
      "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:105)\n",
      "\tat org.apache.spark.sql.classic.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1077)\n",
      "\tat org.apache.spark.sql.classic.Dataset$.ofRows(Dataset.scala:146)\n",
      "\tat org.apache.spark.sql.classic.SparkSession.$anonfun$sql$5(SparkSession.scala:856)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)\n",
      "\tat org.apache.spark.sql.classic.SparkSession.sql(SparkSession.scala:819)\n",
      "\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.executeSQL(SparkConnectPlanner.scala:3587)\n",
      "\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleSqlCommand(SparkConnectPlanner.scala:3411)\n",
      "\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:3288)\n",
      "\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.handleCommand(ExecuteThreadRunner.scala:383)\n",
      "\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1748)\n",
      "\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:75)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.executedPlan(QueryExecution.scala:753)\n",
      "\tat com.databricks.spark.sqlgateway.history.SqlExecutionMetrics.$anonfun$setQueryExecution$1(SqlExecutionMetrics.scala:191)\n",
      "\tat scala.Option.flatMap(Option.scala:283)\n",
      "\tat com.databricks.spark.sqlgateway.history.SqlExecutionMetrics.setQueryExecution(SqlExecutionMetrics.scala:191)\n",
      "\tat com.databricks.spark.sqlgateway.history.SqlGatewayHistorySparkListener.$anonfun$onSqlStart$1(SqlGatewayHistorySparkListener.scala:831)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:114)\n",
      "\tat com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:200)\n",
      "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:105)\n",
      "\tat com.databricks.spark.sqlgateway.history.SqlGatewayHistorySparkListener.com$databricks$spark$sqlgateway$history$SqlGatewayHistorySparkListener$$onSqlStart(SqlGatewayHistorySparkListener.scala:779)\n",
      "\tat com.databricks.spark.sqlgateway.history.SqlGatewayHistorySparkListener$$anonfun$onOtherEventDefault$1.applyOrElse(SqlGatewayHistorySparkListener.scala:249)\n",
      "\tat com.databricks.spark.sqlgateway.history.SqlGatewayHistorySparkListener$$anonfun$onOtherEventDefault$1.applyOrElse(SqlGatewayHistorySparkListener.scala:237)\n",
      "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\n",
      "\tat com.databricks.spark.sqlgateway.history.utils.ScriptStatementHelper$$anonfun$onOtherEvent$1.applyOrElse(ScriptStatementHelper.scala:29)\n",
      "\tat com.databricks.spark.sqlgateway.history.utils.ScriptStatementHelper$$anonfun$onOtherEvent$1.applyOrElse(ScriptStatementHelper.scala:29)\n",
      "\tat scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:270)\n",
      "\tat com.databricks.spark.sqlgateway.history.SqlGatewayHistorySparkListener.$anonfun$onOtherEvent$1(SqlGatewayHistorySparkListener.scala:215)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
      "\tat com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:114)\n",
      "\tat com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:200)\n",
      "\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:105)\n",
      "\tat com.databricks.spark.sqlgateway.history.SqlGatewayHistorySparkListener.onOtherEvent(SqlGatewayHistorySparkListener.scala:215)\n",
      "\tat org.apache.spark.scheduler.SparkListenerBus.doPostEvent(SparkListenerBus.scala:108)\n",
      "\tat org.apache.spark.scheduler.SparkListenerBus.doPostEvent$(SparkListenerBus.scala:28)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:46)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:46)\n",
      "\tat org.apache.spark.util.ListenerBus.postToAll(ListenerBus.scala:208)\n",
      "\tat org.apache.spark.util.ListenerBus.postToAll$(ListenerBus.scala:172)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.super$postToAll(AsyncEventQueue.scala:150)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.$anonfun$dispatch$1(AsyncEventQueue.scala:150)\n",
      "\tat scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.scala:17)\n",
      "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:119)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue$$anon$2.$anonfun$run$1(AsyncEventQueue.scala:115)\n",
      "\tat org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1575)\n",
      "\tat org.apache.spark.scheduler.AsyncEventQueue$$anon$2.run(AsyncEventQueue.scala:115)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py\", line 1932, in _execute_and_fetch_as_iterator\n",
      "    for b in generator:\n",
      "             ^^^^^^^^^\n",
      "  File \"<frozen _collections_abc>\", line 356, in __next__\n",
      "  File \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/reattach.py\", line 141, in send\n",
      "    if not self._has_next():\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/reattach.py\", line 202, in _has_next\n",
      "    raise e\n",
      "  File \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/reattach.py\", line 174, in _has_next\n",
      "    self._current = self._call_iter(\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/reattach.py\", line 307, in _call_iter\n",
      "    raise e\n",
      "  File \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/reattach.py\", line 279, in _call_iter\n",
      "    return iter_fun()\n",
      "           ^^^^^^^^^^\n",
      "  File \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/reattach.py\", line 175, in <lambda>\n",
      "    lambda: next(self._iterator)  # type: ignore[arg-type]\n",
      "            ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py\", line 658, in __iter__\n",
      "    for response in self._call:\n",
      "                    ^^^^^^^^^^\n",
      "  File \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/grpc/_channel.py\", line 538, in __next__\n",
      "    return self._next()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/Users/max.howarth/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/grpc/_channel.py\", line 962, in _next\n",
      "    raise self\n",
      "grpc._channel._MultiThreadedRendezvous: <_MultiThreadedRendezvous of RPC that terminated with:\n",
      "\tstatus = StatusCode.INTERNAL\n",
      "\tdetails = \"[TABLE_OR_VIEW_NOT_FOUND] The table or view `${CATALOG}`.`${SCHEMA}`.`silver_site` cannot be found. Verify the spelling and correctness of the schema and catalog.\n",
      "If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\n",
      "To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 1 pos 12;\n",
      "'SetTableProperties [delta.enableChangeDataFeed=true]\n",
      "+- 'UnresolvedTable [${CATALOG}, ${SCHEMA}, silver_site], ALTER TABLE ... SET TBLPROPERTIES, true, true\n",
      "\"\n",
      "\tdebug_error_string = \"UNKNOWN:Error received from peer  {grpc_message:\"[TABLE_OR_VIEW_NOT_FOUND] The table or view `${CATALOG}`.`${SCHEMA}`.`silver_site` cannot be found. Verify the spelling and correctness of the schema and catalog.\\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 1 pos 12;\\n\\'SetTableProperties [delta.enableChangeDataFeed=true]\\n+- \\'UnresolvedTable [${CATALOG}, ${SCHEMA}, silver_site], ALTER TABLE ... SET TBLPROPERTIES, true, true\\n\", grpc_status:13}\"\n",
      ">\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "[TABLE_OR_VIEW_NOT_FOUND] The table or view `${CATALOG}`.`${SCHEMA}`.`silver_site` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 1 pos 12;\n'SetTableProperties [delta.enableChangeDataFeed=true]\n+- 'UnresolvedTable [${CATALOG}, ${SCHEMA}, silver_site], ALTER TABLE ... SET TBLPROPERTIES, true, true\n\n\nJVM stacktrace:\norg.apache.spark.sql.catalyst.ExtendedAnalysisException\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.tableNotFound(package.scala:94)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2(CheckAnalysis.scala:337)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2$adapted(CheckAnalysis.scala:324)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:312)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:311)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:311)\n\tat scala.collection.immutable.Vector.foreach(Vector.scala:2125)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:311)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0(CheckAnalysis.scala:324)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0$(CheckAnalysis.scala:295)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis0(Analyzer.scala:585)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:280)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:114)\n\tat com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:200)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:105)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:266)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:262)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:585)\n\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$resolveInFixedPoint$1(HybridAnalyzer.scala:439)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:267)\n\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:439)\n\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:98)\n\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:135)\n\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:91)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$2(Analyzer.scala:642)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:425)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:642)\n\tat com.databricks.sql.unity.SAMSnapshotHelper$.visitPlansDuringAnalysis(SAMSnapshotHelper.scala:41)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:634)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$3(QueryExecution.scala:347)\n\tat com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:114)\n\tat com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:200)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:105)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:697)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$8(QueryExecution.scala:832)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withExecutionPhase$1(SQLExecution.scala:158)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:328)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:324)\n\tat com.databricks.util.TracingSpanUtils$.$anonfun$withTracing$4(TracingSpanUtils.scala:235)\n\tat com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:129)\n\tat com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:233)\n\tat com.databricks.tracing.TracingUtils$.withTracing(TracingUtils.scala:296)\n\tat com.databricks.spark.util.DatabricksTracingHelper.withSpan(DatabricksSparkTracingHelper.scala:115)\n\tat com.databricks.spark.util.DBRTracing$.withSpan(DBRTracing.scala:47)\n\tat org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:139)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$7(QueryExecution.scala:832)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1478)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$5(QueryExecution.scala:825)\n\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$4(QueryExecution.scala:822)\n\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$3(QueryExecution.scala:822)\n\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:821)\n\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\tat org.apache.spark.sql.execution.QueryExecution.withQueryExecutionId(QueryExecution.scala:809)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:820)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)\n\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:819)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:329)\n\tat com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:111)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:328)\n\tat scala.util.Try$.apply(Try.scala:217)\n\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1687)\n\tat org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:60)\n\tat org.apache.spark.util.LazyTry.tryT(LazyTry.scala:59)\n\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:75)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:389)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:302)\n\tat org.apache.spark.sql.classic.Dataset$.$anonfun$ofRows$3(Dataset.scala:154)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)\n\tat org.apache.spark.sql.classic.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1077)\n\tat com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:114)\n\tat com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:200)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:105)\n\tat org.apache.spark.sql.classic.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1077)\n\tat org.apache.spark.sql.classic.Dataset$.ofRows(Dataset.scala:146)\n\tat org.apache.spark.sql.classic.SparkSession.$anonfun$sql$5(SparkSession.scala:856)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)\n\tat org.apache.spark.sql.classic.SparkSession.sql(SparkSession.scala:819)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.executeSQL(SparkConnectPlanner.scala:3587)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleSqlCommand(SparkConnectPlanner.scala:3411)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:3288)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.handleCommand(ExecuteThreadRunner.scala:383)\n\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1748)\n\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:75)\n\tat org.apache.spark.sql.execution.QueryExecution.executedPlan(QueryExecution.scala:753)\n\tat com.databricks.spark.sqlgateway.history.SqlExecutionMetrics.$anonfun$setQueryExecution$1(SqlExecutionMetrics.scala:191)\n\tat scala.Option.flatMap(Option.scala:283)\n\tat com.databricks.spark.sqlgateway.history.SqlExecutionMetrics.setQueryExecution(SqlExecutionMetrics.scala:191)\n\tat com.databricks.spark.sqlgateway.history.SqlGatewayHistorySparkListener.$anonfun$onSqlStart$1(SqlGatewayHistorySparkListener.scala:831)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:114)\n\tat com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:200)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:105)\n\tat com.databricks.spark.sqlgateway.history.SqlGatewayHistorySparkListener.com$databricks$spark$sqlgateway$history$SqlGatewayHistorySparkListener$$onSqlStart(SqlGatewayHistorySparkListener.scala:779)\n\tat com.databricks.spark.sqlgateway.history.SqlGatewayHistorySparkListener$$anonfun$onOtherEventDefault$1.applyOrElse(SqlGatewayHistorySparkListener.scala:249)\n\tat com.databricks.spark.sqlgateway.history.SqlGatewayHistorySparkListener$$anonfun$onOtherEventDefault$1.applyOrElse(SqlGatewayHistorySparkListener.scala:237)\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\n\tat com.databricks.spark.sqlgateway.history.utils.ScriptStatementHelper$$anonfun$onOtherEvent$1.applyOrElse(ScriptStatementHelper.scala:29)\n\tat com.databricks.spark.sqlgateway.history.utils.ScriptStatementHelper$$anonfun$onOtherEvent$1.applyOrElse(ScriptStatementHelper.scala:29)\n\tat scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:270)\n\tat com.databricks.spark.sqlgateway.history.SqlGatewayHistorySparkListener.$anonfun$onOtherEvent$1(SqlGatewayHistorySparkListener.scala:215)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:114)\n\tat com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:200)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:105)\n\tat com.databricks.spark.sqlgateway.history.SqlGatewayHistorySparkListener.onOtherEvent(SqlGatewayHistorySparkListener.scala:215)\n\tat org.apache.spark.scheduler.SparkListenerBus.doPostEvent(SparkListenerBus.scala:108)\n\tat org.apache.spark.scheduler.SparkListenerBus.doPostEvent$(SparkListenerBus.scala:28)\n\tat org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:46)\n\tat org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:46)\n\tat org.apache.spark.util.ListenerBus.postToAll(ListenerBus.scala:208)\n\tat org.apache.spark.util.ListenerBus.postToAll$(ListenerBus.scala:172)\n\tat org.apache.spark.scheduler.AsyncEventQueue.super$postToAll(AsyncEventQueue.scala:150)\n\tat org.apache.spark.scheduler.AsyncEventQueue.$anonfun$dispatch$1(AsyncEventQueue.scala:150)\n\tat scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.scala:17)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\n\tat org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:119)\n\tat org.apache.spark.scheduler.AsyncEventQueue$$anon$2.$anonfun$run$1(AsyncEventQueue.scala:115)\n\tat org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1575)\n\tat org.apache.spark.scheduler.AsyncEventQueue$$anon$2.run(AsyncEventQueue.scala:115)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAnalysisException\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m _sqldf\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m _sqldf = \u001b[43mspark\u001b[49m\u001b[43m.\u001b[49m\u001b[43msql\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'''\u001b[39;49m\u001b[33;43mALTER TABLE `$\u001b[39;49m\u001b[38;5;132;43;01m{CATALOG}\u001b[39;49;00m\u001b[33;43m`.`$\u001b[39;49m\u001b[38;5;132;43;01m{SCHEMA}\u001b[39;49;00m\u001b[33;43m`.silver_site SET TBLPROPERTIES (delta.enableChangeDataFeed = true)\u001b[39;49m\u001b[33;43m'''\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m _sqldf\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/session.py:821\u001b[39m, in \u001b[36mSparkSession.sql\u001b[39m\u001b[34m(self, sqlQuery, args, **kwargs)\u001b[39m\n\u001b[32m    818\u001b[39m         _views.append(SubqueryAlias(df._plan, name))\n\u001b[32m    820\u001b[39m cmd = SQL(sqlQuery, _args, _named_args, _views)\n\u001b[32m--> \u001b[39m\u001b[32m821\u001b[39m data, properties, ei = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33msql_command_result\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m properties:\n\u001b[32m    823\u001b[39m     df = DataFrame(CachedRelation(properties[\u001b[33m\"\u001b[39m\u001b[33msql_command_result\u001b[39m\u001b[33m\"\u001b[39m]), \u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py:1481\u001b[39m, in \u001b[36mSparkConnectClient.execute_command\u001b[39m\u001b[34m(self, command, observations, extra_request_metadata)\u001b[39m\n\u001b[32m   1479\u001b[39m     req.user_context.user_id = \u001b[38;5;28mself\u001b[39m._user_id\n\u001b[32m   1480\u001b[39m req.plan.command.CopyFrom(command)\n\u001b[32m-> \u001b[39m\u001b[32m1481\u001b[39m data, _, metrics, observed_metrics, properties = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_and_fetch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1482\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_request_metadata\u001b[49m\n\u001b[32m   1483\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1484\u001b[39m \u001b[38;5;66;03m# Create a query execution object.\u001b[39;00m\n\u001b[32m   1485\u001b[39m ei = ExecutionInfo(metrics, observed_metrics)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py:1970\u001b[39m, in \u001b[36mSparkConnectClient._execute_and_fetch\u001b[39m\u001b[34m(self, req, observations, extra_request_metadata, self_destruct)\u001b[39m\n\u001b[32m   1967\u001b[39m properties: Dict[\u001b[38;5;28mstr\u001b[39m, Any] = {}\n\u001b[32m   1969\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Progress(handlers=\u001b[38;5;28mself\u001b[39m._progress_handlers, operation_id=req.operation_id) \u001b[38;5;28;01mas\u001b[39;00m progress:\n\u001b[32m-> \u001b[39m\u001b[32m1970\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_and_fetch_as_iterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1971\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_request_metadata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress\u001b[49m\n\u001b[32m   1972\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1973\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mStructType\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1974\u001b[39m \u001b[43m            \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py:1946\u001b[39m, in \u001b[36mSparkConnectClient._execute_and_fetch_as_iterator\u001b[39m\u001b[34m(self, req, observations, extra_request_metadata, progress)\u001b[39m\n\u001b[32m   1944\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m kb\n\u001b[32m   1945\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m-> \u001b[39m\u001b[32m1946\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py:2266\u001b[39m, in \u001b[36mSparkConnectClient._handle_error\u001b[39m\u001b[34m(self, error)\u001b[39m\n\u001b[32m   2264\u001b[39m \u001b[38;5;28mself\u001b[39m.thread_local.inside_error_handling = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   2265\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(error, grpc.RpcError):\n\u001b[32m-> \u001b[39m\u001b[32m2266\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_rpc_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2267\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(error, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[32m   2268\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mCannot invoke RPC\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(error) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mclosed\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(error):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/maxatdatabricks@github.com/mobi_agent/.venv/lib/python3.12/site-packages/pyspark/sql/connect/client/core.py:2377\u001b[39m, in \u001b[36mSparkConnectClient._handle_rpc_error\u001b[39m\u001b[34m(self, rpc_error)\u001b[39m\n\u001b[32m   2363\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m SparkConnectGrpcException(\n\u001b[32m   2364\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mPython versions in the Spark Connect client and server are different. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2365\u001b[39m                     \u001b[33m\"\u001b[39m\u001b[33mTo execute user-defined functions, client and server should have the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2373\u001b[39m                         \u001b[33m\"\u001b[39m\u001b[33msqlState\u001b[39m\u001b[33m\"\u001b[39m, default=SparkConnectGrpcException.CLIENT_UNEXPECTED_MISSING_SQL_STATE),\n\u001b[32m   2374\u001b[39m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2375\u001b[39m             \u001b[38;5;66;03m# END-EDGE\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2377\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m convert_exception(\n\u001b[32m   2378\u001b[39m                 info,\n\u001b[32m   2379\u001b[39m                 status.message,\n\u001b[32m   2380\u001b[39m                 \u001b[38;5;28mself\u001b[39m._fetch_enriched_error(info),\n\u001b[32m   2381\u001b[39m                 \u001b[38;5;28mself\u001b[39m._display_server_stack_trace(),\n\u001b[32m   2382\u001b[39m             ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2384\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m SparkConnectGrpcException(\n\u001b[32m   2385\u001b[39m         message=status.message,\n\u001b[32m   2386\u001b[39m         sql_state=SparkConnectGrpcException.CLIENT_UNEXPECTED_MISSING_SQL_STATE,  \u001b[38;5;66;03m# EDGE\u001b[39;00m\n\u001b[32m   2387\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2388\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mAnalysisException\u001b[39m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `${CATALOG}`.`${SCHEMA}`.`silver_site` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 1 pos 12;\n'SetTableProperties [delta.enableChangeDataFeed=true]\n+- 'UnresolvedTable [${CATALOG}, ${SCHEMA}, silver_site], ALTER TABLE ... SET TBLPROPERTIES, true, true\n\n\nJVM stacktrace:\norg.apache.spark.sql.catalyst.ExtendedAnalysisException\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.tableNotFound(package.scala:94)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2(CheckAnalysis.scala:337)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis0$2$adapted(CheckAnalysis.scala:324)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:312)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1(TreeNode.scala:311)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$foreachUp$1$adapted(TreeNode.scala:311)\n\tat scala.collection.immutable.Vector.foreach(Vector.scala:2125)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:311)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0(CheckAnalysis.scala:324)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis0$(CheckAnalysis.scala:295)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis0(Analyzer.scala:585)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.$anonfun$checkAnalysis$1(CheckAnalysis.scala:280)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:114)\n\tat com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:200)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:105)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis(CheckAnalysis.scala:266)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis.checkAnalysis$(CheckAnalysis.scala:262)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:585)\n\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$resolveInFixedPoint$1(HybridAnalyzer.scala:439)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:267)\n\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.resolveInFixedPoint(HybridAnalyzer.scala:439)\n\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.$anonfun$apply$1(HybridAnalyzer.scala:98)\n\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.withTrackedAnalyzerBridgeState(HybridAnalyzer.scala:135)\n\tat org.apache.spark.sql.catalyst.analysis.resolver.HybridAnalyzer.apply(HybridAnalyzer.scala:91)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$2(Analyzer.scala:642)\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:425)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:642)\n\tat com.databricks.sql.unity.SAMSnapshotHelper$.visitPlansDuringAnalysis(SAMSnapshotHelper.scala:41)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:634)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$3(QueryExecution.scala:347)\n\tat com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:114)\n\tat com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:200)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:105)\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:697)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$8(QueryExecution.scala:832)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withExecutionPhase$1(SQLExecution.scala:158)\n\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:328)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\n\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:324)\n\tat com.databricks.util.TracingSpanUtils$.$anonfun$withTracing$4(TracingSpanUtils.scala:235)\n\tat com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:129)\n\tat com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:233)\n\tat com.databricks.tracing.TracingUtils$.withTracing(TracingUtils.scala:296)\n\tat com.databricks.spark.util.DatabricksTracingHelper.withSpan(DatabricksSparkTracingHelper.scala:115)\n\tat com.databricks.spark.util.DBRTracing$.withSpan(DBRTracing.scala:47)\n\tat org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:139)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$7(QueryExecution.scala:832)\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1478)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$5(QueryExecution.scala:825)\n\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$4(QueryExecution.scala:822)\n\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$3(QueryExecution.scala:822)\n\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:821)\n\tat com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)\n\tat org.apache.spark.sql.execution.QueryExecution.withQueryExecutionId(QueryExecution.scala:809)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:820)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)\n\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:819)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$2(QueryExecution.scala:329)\n\tat com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:111)\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyAnalyzed$1(QueryExecution.scala:328)\n\tat scala.util.Try$.apply(Try.scala:217)\n\tat org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1687)\n\tat org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:60)\n\tat org.apache.spark.util.LazyTry.tryT(LazyTry.scala:59)\n\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:75)\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:389)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:302)\n\tat org.apache.spark.sql.classic.Dataset$.$anonfun$ofRows$3(Dataset.scala:154)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)\n\tat org.apache.spark.sql.classic.SparkSession.$anonfun$withActiveAndFrameProfiler$1(SparkSession.scala:1077)\n\tat com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:114)\n\tat com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:200)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:105)\n\tat org.apache.spark.sql.classic.SparkSession.withActiveAndFrameProfiler(SparkSession.scala:1077)\n\tat org.apache.spark.sql.classic.Dataset$.ofRows(Dataset.scala:146)\n\tat org.apache.spark.sql.classic.SparkSession.$anonfun$sql$5(SparkSession.scala:856)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)\n\tat org.apache.spark.sql.classic.SparkSession.sql(SparkSession.scala:819)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.executeSQL(SparkConnectPlanner.scala:3587)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleSqlCommand(SparkConnectPlanner.scala:3411)\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:3288)\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.handleCommand(ExecuteThreadRunner.scala:383)\n\tat org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1748)\n\tat org.apache.spark.util.LazyTry.get(LazyTry.scala:75)\n\tat org.apache.spark.sql.execution.QueryExecution.executedPlan(QueryExecution.scala:753)\n\tat com.databricks.spark.sqlgateway.history.SqlExecutionMetrics.$anonfun$setQueryExecution$1(SqlExecutionMetrics.scala:191)\n\tat scala.Option.flatMap(Option.scala:283)\n\tat com.databricks.spark.sqlgateway.history.SqlExecutionMetrics.setQueryExecution(SqlExecutionMetrics.scala:191)\n\tat com.databricks.spark.sqlgateway.history.SqlGatewayHistorySparkListener.$anonfun$onSqlStart$1(SqlGatewayHistorySparkListener.scala:831)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:114)\n\tat com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:200)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:105)\n\tat com.databricks.spark.sqlgateway.history.SqlGatewayHistorySparkListener.com$databricks$spark$sqlgateway$history$SqlGatewayHistorySparkListener$$onSqlStart(SqlGatewayHistorySparkListener.scala:779)\n\tat com.databricks.spark.sqlgateway.history.SqlGatewayHistorySparkListener$$anonfun$onOtherEventDefault$1.applyOrElse(SqlGatewayHistorySparkListener.scala:249)\n\tat com.databricks.spark.sqlgateway.history.SqlGatewayHistorySparkListener$$anonfun$onOtherEventDefault$1.applyOrElse(SqlGatewayHistorySparkListener.scala:237)\n\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\n\tat com.databricks.spark.sqlgateway.history.utils.ScriptStatementHelper$$anonfun$onOtherEvent$1.applyOrElse(ScriptStatementHelper.scala:29)\n\tat com.databricks.spark.sqlgateway.history.utils.ScriptStatementHelper$$anonfun$onOtherEvent$1.applyOrElse(ScriptStatementHelper.scala:29)\n\tat scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:270)\n\tat com.databricks.spark.sqlgateway.history.SqlGatewayHistorySparkListener.$anonfun$onOtherEvent$1(SqlGatewayHistorySparkListener.scala:215)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n\tat com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:114)\n\tat com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:200)\n\tat com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:105)\n\tat com.databricks.spark.sqlgateway.history.SqlGatewayHistorySparkListener.onOtherEvent(SqlGatewayHistorySparkListener.scala:215)\n\tat org.apache.spark.scheduler.SparkListenerBus.doPostEvent(SparkListenerBus.scala:108)\n\tat org.apache.spark.scheduler.SparkListenerBus.doPostEvent$(SparkListenerBus.scala:28)\n\tat org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:46)\n\tat org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:46)\n\tat org.apache.spark.util.ListenerBus.postToAll(ListenerBus.scala:208)\n\tat org.apache.spark.util.ListenerBus.postToAll$(ListenerBus.scala:172)\n\tat org.apache.spark.scheduler.AsyncEventQueue.super$postToAll(AsyncEventQueue.scala:150)\n\tat org.apache.spark.scheduler.AsyncEventQueue.$anonfun$dispatch$1(AsyncEventQueue.scala:150)\n\tat scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.scala:17)\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\n\tat org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:119)\n\tat org.apache.spark.scheduler.AsyncEventQueue$$anon$2.$anonfun$run$1(AsyncEventQueue.scala:115)\n\tat org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1575)\n\tat org.apache.spark.scheduler.AsyncEventQueue$$anon$2.run(AsyncEventQueue.scala:115)"
     ]
    }
   ],
   "source": [
    "%sql\n",
    "ALTER TABLE `${CATALOG}`.`${SCHEMA}`.silver_site SET TBLPROPERTIES (delta.enableChangeDataFeed = true);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adf49ee2-f70f-4151-862e-89b5bde84b2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create Vector Search Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4108690e-94b0-4ba4-80e2-e725183ba86c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.vector_search.client import VectorSearchClient\n",
    "\n",
    "client = VectorSearchClient(disable_notice=True)\n",
    "client.create_endpoint(\n",
    "    name=\"mobi_vs_endpoint\",\n",
    "    endpoint_type=\"STANDARD\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebe8146d-bf3b-41a8-adc2-4abd92e9255b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create Vector Search Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30b07887-4432-4b2c-851c-9b2a3925d029",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "index = client.create_delta_sync_index(\n",
    "    endpoint_name=\"mobi_vs_endpoint\",\n",
    "    source_table_name=f\"`{CATALOG}`.`{SCHEMA}`.silver_site\",\n",
    "    index_name=f\"{CATALOG}.{SCHEMA}.mobi_site_index\",\n",
    "    pipeline_type=\"TRIGGERED\",\n",
    "    primary_key=\"site_page_id\",                # Must be present in your table\n",
    "    embedding_source_column=\"content_md\",  # Text column for embedding\n",
    "    embedding_model_endpoint_name=\"databricks-gte-large-en\" # or any available model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "520fe692-33c7-4817-8eb9-9e2db312e268",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT\n",
    "  *,\n",
    "  floor(unique_id / 5) AS unique_id_bin_10\n",
    "FROM vector_search(\n",
    "  index=>'`${CATALOG}`.`${SCHEMA}`.documents_index',\n",
    "  query_text=>\"Trip Fares\",\n",
    "  num_results=>50,\n",
    "  query_type=>'hybrid'\n",
    ")\n",
    "ORDER BY unique_id_bin_10 DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2c962cd-35f3-47ef-8e94-464d5e9dd99a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE FUNCTION `${CATALOG}`.`${SCHEMA}`.site_search(\n",
    "  description STRING COMMENT 'A search of mobi documents'\n",
    ")\n",
    "RETURNS TABLE (\n",
    "  unique_id INTEGER,\n",
    "  file_name STRING,\n",
    "  value STRING,\n",
    "  search_score STRING\n",
    ")\n",
    "COMMENT 'Returns the top three documents matching semantic search.\n",
    "'\n",
    "RETURN\n",
    "SELECT *\n",
    "FROM vector_search(\n",
    "  index=>'`${CATALOG}`.`${SCHEMA}`.mobi_site_index',\n",
    "  query_text=>description,\n",
    "  num_results=>3,\n",
    "  query_type=>'hybrid'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66460199-4ccd-46b5-b32b-088519fc28fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM `${CATALOG}`.`${SCHEMA}`.doc_search(\"Trip Fares\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7783426245318987,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "03_vector_search",
   "widgets": {
    "catalog": {
     "currentValue": "max-howarth-demos",
     "nuid": "be283ed4-190f-445a-a199-8beb7303a79f",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "max-howarth-demos",
      "label": null,
      "name": "catalog",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "max-howarth-demos",
      "label": null,
      "name": "catalog",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "schema": {
     "currentValue": "vancouver-hackathon-1125",
     "nuid": "6e70e028-8916-4b9a-84d9-630a209c77e4",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "vancouver-hackathon-1125",
      "label": null,
      "name": "schema",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "vancouver-hackathon-1125",
      "label": null,
      "name": "schema",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
